{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_CUDNN_USE_AUTOTUNE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:24:15.146697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:24:16.479614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:24:16.479742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.483853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.483965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.484054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.484139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.485276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 13:24:16.486166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.486288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.486376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.884132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.884273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.884370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-17 13:24:16.884448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 1024\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_CHANNEL = 3\n",
    "vocabulary_size = 0\n",
    "\n",
    "caption_embedding_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word2Id_dict), output_dim=EMBEDDING_DIM, input_length=20),\n",
    "])\n",
    "\n",
    "def training_data_generator(image_path, caption):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    caption = tf.cast(caption, tf.int32)\n",
    "    caption_embedding = caption_embedding_model(caption)\n",
    "    caption_embedding = tf.reduce_mean(caption_embedding, axis=0)\n",
    "    \n",
    "    return img, caption_embedding\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator):\n",
    "    # load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, caption))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_data_generator(caption, index):\n",
    "    caption = tf.cast(caption, tf.float32)\n",
    "    caption_embedding = caption_embedding_model(caption)\n",
    "    caption_embedding = tf.reduce_mean(caption_embedding, axis=0)\n",
    "    return caption, caption_embedding\n",
    "\n",
    "def testing_dataset_generator(batch_size, data_generator):\n",
    "    data = pd.read_pickle('./dataset/testData.pkl')\n",
    "    captions = data['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_IMAGE_HEIGHT = 256\n",
    "H_IMAGE_WIDTH = 256\n",
    "H_IMAGE_CHANNEL = 3\n",
    "\n",
    "caption_embedding_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word2Id_dict), output_dim=EMBEDDING_DIM, input_length=20),\n",
    "])\n",
    "\n",
    "def H_training_data_generator(image_path, caption):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[H_IMAGE_HEIGHT, H_IMAGE_WIDTH])\n",
    "    img.set_shape([H_IMAGE_HEIGHT, H_IMAGE_WIDTH, H_IMAGE_CHANNEL])\n",
    "    caption = tf.cast(caption, tf.int32)\n",
    "    caption_embedding = caption_embedding_model(caption)\n",
    "    caption_embedding = tf.reduce_mean(caption_embedding, axis=0)\n",
    "    \n",
    "    return img, caption_embedding\n",
    "\n",
    "def H_dataset_generator(filenames, batch_size, data_generator):\n",
    "    # load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, caption))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_c(x):\n",
    "    mean = x[:,:128]\n",
    "    log_sigma = x[:,128:]\n",
    "    stddev = tf.exp(log_sigma)\n",
    "    epsilon = tf.random.normal((mean.shape[1],),dtype=tf.int32)\n",
    "    c = stddev * epsilon + mean\n",
    "    return c\n",
    "\n",
    "class CA(keras.Model):\n",
    "    \"\"\"\n",
    "    Get conditioning augmentation model.\n",
    "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CA,self).__init__()\n",
    "        self.fc = layers.Dense(256)\n",
    "        self.activation  = layers.LeakyReLU(alpha=0.2)\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.activation(self.fc(inputs))\n",
    "        return x\n",
    "\n",
    "class Embedding_Compressor(keras.Model):\n",
    "    \"\"\"\n",
    "    Build embedding compressor model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Embedding_Compressor,self).__init__()\n",
    "        self.fc = layers.Dense(128)\n",
    "        self.activation = layers.ReLU()\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.activation(self.fc(inputs))\n",
    "        return x\n",
    "\n",
    "class Generator_stage1(keras.Model):\n",
    "    \"\"\"\n",
    "    Builds a generator model used in Stage-I\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator_stage1,self).__init__()\n",
    "        self.ca_fc = layers.Dense(256)\n",
    "        self.ca_activation = layers.LeakyReLU(alpha=0.2)\n",
    "        #self.lambda1 = layers.Lambda(generator_c)\n",
    "        #self.mean1 = layers.Dense(128)\n",
    "        #self.log_sigma1 = layers.Dense(128)\n",
    "        self.fc1 = layers.Dense(128 * 8 * 4 * 4,use_bias=False)\n",
    "        self.activation = layers.ReLU()\n",
    "        \n",
    "        self.upsampling1 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv1 = layers.Conv2D(512,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac1 = layers.ReLU()\n",
    "        \n",
    "        self.upsampling2 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv2 = layers.Conv2D(256,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "\n",
    "        self.upsampling3 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv3 = layers.Conv2D(128,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.ReLU()\n",
    "\n",
    "        self.upsampling4 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv4 = layers.Conv2D(64,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.ReLU()\n",
    "\n",
    "        self.conv5 = layers.Conv2D(3,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        mean_logsigma = tf.split(self.ca_activation(self.ca_fc(inputs[0])),num_or_size_splits=2,axis=-1)\n",
    "        #print(mean_logsigma.shape)\n",
    "        #c = self.lambda1(mean_logsigma)\n",
    "        #mean_logsigma_split = tf.split(mean_logsigma,num_or_size_splits=2,axis=-1)\n",
    "        mean = mean_logsigma[0]\n",
    "        log_sigma = mean_logsigma[1]\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = stddev * inputs[2] + mean\n",
    "        #print(c.shape)\n",
    "        gen_inputs = tf.concat([c,inputs[1]],axis=1)\n",
    "        #print(gen_inputs.shape)\n",
    "        x = self.activation(self.fc1(gen_inputs))\n",
    "        #print(x.shape)\n",
    "        x = tf.reshape(x,shape=(-1,4,4,128*8))\n",
    "        x = self.ac1(self.bn1(self.conv1(self.upsampling1(x)),training=training))\n",
    "        x = self.ac2(self.bn2(self.conv2(self.upsampling2(x)),training=training))\n",
    "        x = self.ac3(self.bn3(self.conv3(self.upsampling3(x)),training=training))\n",
    "        x = self.ac4(self.bn4(self.conv4(self.upsampling4(x)),training=training))\n",
    "        x = self.conv5(x)\n",
    "        x = tf.tanh(x)\n",
    "        #print(x.shape)\n",
    "        return x,mean_logsigma\n",
    "\n",
    "class Discriminator_stage1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_stage1,self).__init__()\n",
    "        self.e_fc = layers.Dense(128)\n",
    "        self.e_ac = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.ac1 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv2 = layers.Conv2D(128,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv3 = layers.Conv2D(256,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv5 = layers.Conv2D(512,kernel_size=1,padding='same',strides=1)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.ac1(self.conv1(inputs[0]))\n",
    "        #print(x.shape)\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.ac4(self.bn3(self.conv4(x),training=training))\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        input_layer2 = self.e_ac(self.e_fc(inputs[1]))\n",
    "        #print(input_layer2.shape)\n",
    "        input_layer2 = tf.reshape(input_layer2,shape=(-1,1,1,128))\n",
    "        #print(input_layer2.shape)\n",
    "        input_layer2 = tf.tile(input_layer2,[1,4,4,1])\n",
    "        #print(input_layer2.shape)\n",
    "        x = tf.concat([x,input_layer2],axis=-1)\n",
    "        #print(x.shape)\n",
    "        x = self.ac5(self.bn4(self.conv5(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        #print(x.shape)\n",
    "        x = tf.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_block(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Residual_block,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(128*4,kernel_size=(3,3),padding='same',strides=1)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac1 = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(128*4,kernel_size=(3,3),padding='same',strides=1)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.bn1(self.conv1(inputs),training=training)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn2(self.conv2(x),training=training)\n",
    "        x = layers.add([x,inputs])\n",
    "        x = self.ac2(x)\n",
    "        return x\n",
    "\n",
    "class Generator_stage2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator_stage2,self).__init__()\n",
    "        self.ca_fc = layers.Dense(256)\n",
    "        self.ca_activation = layers.LeakyReLU(alpha=0.2)\n",
    "        #self.mean1 = layers.Dense(128)\n",
    "        #self.log_sigma1 = layers.Dense(128)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(128,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.ac1 = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(256,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "        self.conv3 = layers.Conv2D(512,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.ReLU()\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.ReLU()\n",
    "\n",
    "        self.rb1 = Residual_block()\n",
    "        self.rb2 = Residual_block()\n",
    "        self.rb3 = Residual_block()\n",
    "        self.rb4 = Residual_block()\n",
    "        \n",
    "        self.upsampling1 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv5 = layers.Conv2D(512,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.ReLU()\n",
    "\n",
    "        self.upsampling2 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv6 = layers.Conv2D(256,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.ac6 = layers.ReLU()\n",
    "\n",
    "        self.upsampling3 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv7 = layers.Conv2D(128,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn6 = layers.BatchNormalization()\n",
    "        self.ac7 = layers.ReLU()\n",
    "\n",
    "        self.upsampling4 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv8 = layers.Conv2D(64,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn7 = layers.BatchNormalization()\n",
    "        self.ac8 = layers.ReLU()\n",
    "\n",
    "        self.conv9 = layers.Conv2D(3,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    def call(self,inputs,training):\n",
    "        #CA Network\n",
    "        mean_logsigma = tf.split(self.ca_activation(self.ca_fc(inputs[0])),num_or_size_splits=2,axis=-1)\n",
    "        #mean_logsigma = self.ca_activation(self.ca_fc(inputs[0]))\n",
    "        mean = mean_logsigma[0]\n",
    "        log_sigma = mean_logsigma[1]\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = stddev * inputs[2] + mean\n",
    "        #c = tf.concat([c,inputs[1]],axis=1)\n",
    "        #Image Encoder\n",
    "        x = self.ac1(self.conv1(inputs[1]))\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        c = tf.expand_dims(c,axis=1)\n",
    "        c = tf.expand_dims(c,axis=1)\n",
    "        c = tf.tile(c,[1,16,16,1])\n",
    "        #Concatenation\n",
    "        c_code = tf.concat([c,x],axis=3)\n",
    "        #Residual Block\n",
    "        x = self.ac4(self.bn3(self.conv4(c_code),training=training))\n",
    "        x = self.rb1(x)\n",
    "        x = self.rb2(x)\n",
    "        x = self.rb3(x)\n",
    "        x = self.rb4(x)\n",
    "        #Upsampling block\n",
    "        x = self.ac5(self.bn4(self.conv5(self.upsampling1(x)),training=training))\n",
    "        x = self.ac6(self.bn5(self.conv6(self.upsampling2(x)),training=training))\n",
    "        x = self.ac7(self.bn6(self.conv7(self.upsampling3(x)),training=training))\n",
    "        x = self.ac8(self.bn7(self.conv8(self.upsampling4(x)),training=training))\n",
    "        x = self.conv9(x)\n",
    "        x = tf.tanh(x)\n",
    "        return x,mean_logsigma\n",
    "\n",
    "class Discriminator_stage2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_stage2,self).__init__()\n",
    "        self.e_fc = layers.Dense(128)\n",
    "        self.e_ac = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.ac1 = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(128,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv3 = layers.Conv2D(256,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv5 = layers.Conv2D(1024,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv6 = layers.Conv2D(2048,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.ac6 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv7 = layers.Conv2D(1024,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn6 = layers.BatchNormalization()\n",
    "        self.ac7 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv8 = layers.Conv2D(512,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn7 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv9 = layers.Conv2D(128,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn8 = layers.BatchNormalization()\n",
    "        self.ac8 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv10 = layers.Conv2D(128,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn9 = layers.BatchNormalization()\n",
    "        self.ac9 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv11 = layers.Conv2D(512,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn10 = layers.BatchNormalization()\n",
    "\n",
    "        self.ac10 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv12 = layers.Conv2D(64*8,kernel_size=1,strides=1,padding='same')\n",
    "        self.bn11 = layers.BatchNormalization()\n",
    "        self.ac11 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.ac1(self.conv1(inputs[0]))\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        x = self.ac4(self.bn3(self.conv4(x),training=training))\n",
    "        x = self.ac5(self.bn4(self.conv5(x),training=training))\n",
    "        x = self.ac6(self.bn5(self.conv6(x),training=training))\n",
    "        x = self.ac7(self.bn6(self.conv7(x),training=training))\n",
    "        x = self.bn7(self.conv8(x))\n",
    "        \n",
    "        x2 = self.ac8(self.bn8(self.conv9(x),training=training))\n",
    "        x2 = self.ac9(self.bn9(self.conv10(x2),training=training))\n",
    "        x2 = self.bn10(self.conv11(x2))\n",
    "\n",
    "        added_x = layers.add([x,x2])\n",
    "        added_x = self.ac10(added_x)\n",
    "\n",
    "        input_layer2 = self.e_ac(self.e_fc(inputs[1]))\n",
    "        input_layer2 = tf.reshape(input_layer2,shape=(-1,1,1,128))\n",
    "        input_layer2 = tf.tile(input_layer2,[1,4,4,1])\n",
    "        x3 = tf.concat([added_x,input_layer2],axis=-1)\n",
    "\n",
    "        x3 = self.ac11(self.bn11(self.conv12(x3),training=training))\n",
    "        x3 = self.flatten(x3)\n",
    "        x3 = self.fc(x3)\n",
    "        x3 = tf.sigmoid(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celoss_zeros(logits):\n",
    "\t# 计算属于与标签为0的交叉熵，使用标签平滑\n",
    "    y = tf.ones_like(logits) * 0.1\n",
    "    loss = keras.losses.binary_crossentropy(y,logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def celoss_ones(logits):\n",
    "    # 计算属于与标签为1的交叉熵，使用标签平滑\n",
    "    y = tf.ones_like(logits) * 0.9\n",
    "    loss = keras.losses.binary_crossentropy(y, logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def KL_loss(logits):\n",
    "    mean = logits[0]\n",
    "    logsigma = logits[1]\n",
    "    loss = -logsigma + 0.5 * (-1 + tf.exp(2. * logsigma) + tf.square(mean))\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def d_loss_fn(batch_size,generator,discriminator,img_batch,embedding_batch,z_noise,condition_var,training):\n",
    "    # 采样生成图片\n",
    "    # print('======================================================')\n",
    "    # print(embedding_batch.shape)\n",
    "    fake_images,_ = generator([embedding_batch,z_noise,condition_var],training)\n",
    "    # print('======================================================')\n",
    "    # 判定生成图片\n",
    "    d_fake_logits = discriminator([fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    # 判定真实图片\n",
    "    d_real_logits = discriminator([img_batch,embedding_batch], training)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    # 判定不符嵌入\n",
    "    d_wrong_logits = discriminator([img_batch[:(batch_size-1)],embedding_batch[1:]],training)\n",
    "    d_loss_wrong = celoss_zeros(d_wrong_logits)\n",
    "    loss = d_loss_fake + d_loss_real + d_loss_wrong\n",
    "    return loss\n",
    "\n",
    "def g_loss_fn(generator,discriminator,embedding_batch,z_noise,condition_var,training):\n",
    "    fake_images,mean_logsigma = generator([embedding_batch,z_noise,condition_var],training)\n",
    "    d_fake_logits = discriminator([fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_ones(d_fake_logits)\n",
    "    d_KL_fake = KL_loss(mean_logsigma)\n",
    "    loss = d_loss_fake + 2.0 * d_KL_fake\n",
    "    return loss\n",
    "\n",
    "def d_loss_fn_stage2(batch_size=64,\n",
    "                     gen_stage1=None,\n",
    "                     gen_stage2=None,\n",
    "                     dis_stage2=None,\n",
    "                     image_batch=None,\n",
    "                     embedding_batch=None,\n",
    "                     z_noise=None,\n",
    "                     condition_var=None,\n",
    "                     training=False):\n",
    "    lr_fake_images,_ = gen_stage1([embedding_batch,z_noise,condition_var])\n",
    "    hr_fake_images,_ = gen_stage2([embedding_batch,lr_fake_images,condition_var],training)\n",
    "    # 判定生成图片\n",
    "    d_fake_logits = dis_stage2([hr_fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    # 判定真实图片\n",
    "    d_real_logits = dis_stage2([image_batch,embedding_batch], training)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    # 判定不符嵌入\n",
    "    d_wrong_logits = dis_stage2([image_batch[:(batch_size-1)],embedding_batch[1:]],training)\n",
    "    d_loss_wrong = celoss_zeros(d_wrong_logits)\n",
    "    loss = d_loss_fake + d_loss_real + d_loss_wrong\n",
    "    return loss\n",
    "\n",
    "def g_loss_fn_stage2(gen_stage1=None,\n",
    "                     gen_stage2=None,\n",
    "                     dis_stage2=None,\n",
    "                     embedding_batch=None,\n",
    "                     z_noise=None,\n",
    "                     condition_var=None,\n",
    "                     training=False):\n",
    "    lr_fake_images,_ = gen_stage1([embedding_batch,z_noise,condition_var])\n",
    "    hr_fake_images,mean_logsigma = gen_stage2([embedding_batch,lr_fake_images,condition_var],training)\n",
    "    d_fake_logits = dis_stage2([hr_fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_ones(d_fake_logits)\n",
    "    d_KL_fake = KL_loss(mean_logsigma)\n",
    "    loss = d_loss_fake + 2.0 * d_KL_fake\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片保存函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(val_out,val_block_size,image_path,color_mode):\n",
    "    def preprocessing(img):\n",
    "        img = ((img + 1.0)*(255./2)).astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocessed = preprocessing(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocessed[b,:,:,:]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row,preprocessed[b,:,:,:]),axis=1)\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (20,).\n",
      "==================================================\n",
      "index: 0   caption: this white and purple flower has fragile petals and soft stamens <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 1   caption: this flower has four large wide pink petals with white centers and vein like markings <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 2   caption: a flower with broad white and pink ribbed petals and yellow stamen <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 3   caption: one prominet pistil with alarger stigam and many stamens with anthers <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 4   caption: leaves are green in color petals are light pink in color <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 5   caption: this flower is bright pink with overlapping petals and a lime green pistil <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 6   caption: this flower is white and yellow in color with petals that are multi colored <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "index: 7   caption: this flower has 4 leaves three are purple and yellow with lines and one is solid purple <PAD> <PAD> <PAD> \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2848656/2180266409.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  caption = caption.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "z = tf.random.normal([64,100])\n",
    "db_test = testing_dataset_generator(8, testing_data_generator)\n",
    "db_test = iter(db_test)\n",
    "caption ,embeddings_test = next(db_test)\n",
    "embeddings_test = np.repeat(embeddings_test, 8, axis=0)\n",
    "\n",
    "caption = caption.numpy()\n",
    "print('==================================================')\n",
    "for i, c in enumerate(caption):\n",
    "    s = \"\"\n",
    "    for id in c :\n",
    "        s_id = str(int(id))\n",
    "        s += id2word_dict[s_id] + \" \"\n",
    "    print(f'index: {i}   caption: {s}')\n",
    "\n",
    "print('==================================================')\n",
    "\n",
    "def main_stage1():\n",
    "    data_dir = \"./birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 64\n",
    "    batch_size = 32\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 100\n",
    "    condition_dim = 128\n",
    "    training=True\n",
    "\n",
    "    d_optimizer = keras.optimizers.Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    g_optimizer = keras.optimizers.Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "\n",
    "    db_train = dataset_generator('./dataset/text2ImgData.pkl', batch_size, training_data_generator)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    gen = Generator_stage1()\n",
    "    gen.build([[4,1024],[4,100],[128]]) # [embedding_batch,z_noise,condition_var]\n",
    "    try:\n",
    "        gen.load_weights(\"stage1_gen.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    dis = Discriminator_stage1()\n",
    "    dis.build([[4,64,64,3],[4,1024]])\n",
    "    try:\n",
    "        dis.load_weights(\"stage1_dis.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    #real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    #fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "    for epoch in range(epochs):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for index,(x,embedding) in enumerate(db_train):\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn(batch_size,gen,dis,x,embedding,z_noise,condition_var,training)\n",
    "            grads = tape.gradient(d_loss,dis.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads,dis.trainable_variables))\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                g_loss = g_loss_fn(gen,dis,embedding,z_noise,condition_var,training)\n",
    "            grads = tape.gradient(g_loss,gen.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(grads,gen.trainable_variables))\n",
    "            # print(f'batch: {index}  // d_loss: {d_loss}  // g_loss: {g_loss}')\n",
    "        if epoch % 2 == 0:\n",
    "            print(epoch,'d_loss:',float(d_loss),'g_loss:',float(g_loss))\n",
    "            #可视化\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            fake_image,_ = gen([embeddings_test,z,condition_var],training=False)\n",
    "            img_path = r'testout/ganstage1-{}.png'.format(epoch)\n",
    "            save_result(fake_image.numpy(),8,img_path,color_mode='P')\n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "        if epoch % 5 == 0:\n",
    "            timestamp = int(time.time())\n",
    "            gen.save_weights(f\"./weight/stage1_gen_{epoch}_{timestamp}.h5\")\n",
    "            dis.save_weights(f\"./weight/stage1_dis_{epoch}_{timestamp}.h5\")\n",
    "\n",
    "def main_stage2():\n",
    "    image_size = 256\n",
    "    batch_size = 16\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 100\n",
    "    condition_dim = 128\n",
    "    training=True\n",
    "\n",
    "\n",
    "\n",
    "    d_optimizer = keras.optimizers.Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    g_optimizer = keras.optimizers.Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    #Load dataset\n",
    "    db_hr_train = H_dataset_generator('./dataset/text2ImgData.pkl', batch_size, H_training_data_generator)\n",
    "    \n",
    "\n",
    "    # db_hr_test = testing_dataset_generator(8, testing_data_generator)\n",
    "    # db_hr_test = iter(db_hr_test)\n",
    "    # embeddings_test = next(db_hr_test)\n",
    "    # embeddings_test = np.repeat(embeddings_test, 8, axis=0)\n",
    "    \n",
    "    gen_stage1 = Generator_stage1()\n",
    "    gen_stage1.build([[4,1024],[4,100],[128]])\n",
    "    try:\n",
    "        gen_stage1.load_weights(\"weight/stage1_dis_60_1702786016.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    gen_stage2 = Generator_stage2()\n",
    "    gen_stage2.build([[4,1024],[4,64,64,3],[128]])\n",
    "    try:\n",
    "        gen_stage2.load_weights(\"stage2_gen.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    dis_stage2 = Discriminator_stage2()\n",
    "    dis_stage2.build([[4,256,256,3],[4,1024]])\n",
    "    try:\n",
    "        dis_stage2.load_weights(\"stage2_dis.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for index,(x,embedding) in enumerate(db_hr_train):\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn_stage2(batch_size=batch_size,\n",
    "                                          gen_stage1=gen_stage1,\n",
    "                                          gen_stage2=gen_stage2,\n",
    "                                          dis_stage2=dis_stage2,\n",
    "                                          image_batch=x,\n",
    "                                          embedding_batch=embedding,\n",
    "                                          z_noise=z_noise,\n",
    "                                          condition_var=condition_var,\n",
    "                                          training=training)\n",
    "            grads = tape.gradient(d_loss,dis_stage2.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads,dis_stage2.trainable_variables))\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                g_loss = g_loss_fn_stage2(gen_stage1=gen_stage1,\n",
    "                                          gen_stage2=gen_stage2,\n",
    "                                          dis_stage2=dis_stage2,\n",
    "                                          embedding_batch=embedding,\n",
    "                                          z_noise=z_noise,\n",
    "                                          condition_var=condition_var,\n",
    "                                          training=training)\n",
    "            grads = tape.gradient(g_loss,gen_stage2.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(grads,gen_stage2.trainable_variables))\n",
    "            # print(f'batch: {index}  // d_loss: {d_loss}  // g_loss: {g_loss}')\n",
    "        if epoch % 2 == 0:\n",
    "            print(epoch,'d_loss:',float(d_loss),'g_loss:',float(g_loss))\n",
    "            #可视化\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            lr_fake_image,_ = gen_stage1([embeddings_test,z,condition_var],training=False)\n",
    "            hr_fake_image,_ = gen_stage2([embeddings_test,lr_fake_image,condition_var],training=False)\n",
    "            img_path = r'testout/ganstage2-{}.png'.format(epoch)\n",
    "            save_result(hr_fake_image.numpy(),8,img_path,color_mode='P')\n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "        if epoch % 5 == 0:\n",
    "            timestamp = int(time.time())\n",
    "            gen_stage2.save_weights(f\"./weight/stage2_gen_{epoch}_{timestamp}.h5\")\n",
    "            dis_stage2.save_weights(f\"./weight/stage2_dis_{epoch}_{timestamp}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (20,).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s111062697/miniconda3/envs/eric/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/tmp/ipykernel_2848656/2805937485.py:33: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  caption = caption.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight count mismatch for layer #8 (named conv2d_3 in the current model, conv2d_9 in the save file). Layer expects 1 weight(s). Received 2 saved weight(s)\n",
      "[Errno 2] Unable to open file (unable to open file: name = 'stage2_gen.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "[Errno 2] Unable to open file (unable to open file: name = 'stage2_dis.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:24:25.876380: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-17 13:24:25.982372: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-12-17 13:24:31.494588: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:31.634716: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:31.705062: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:31.773138: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:31.847698: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:31.928275: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:24:32.037161: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 d_loss: 1.724459171295166 g_loss: 2.167837142944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 13:27:33.020514: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:27:33.020544: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 13:27:33.020557: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 d_loss: 1.7338581085205078 g_loss: 1.285855770111084\n",
      "4 d_loss: 1.1576504707336426 g_loss: 0.8608639240264893\n",
      "6 d_loss: 1.5791363716125488 g_loss: 1.086782455444336\n",
      "8 d_loss: 2.046070098876953 g_loss: 1.1735401153564453\n",
      "10 d_loss: 1.696197509765625 g_loss: 1.0490825176239014\n",
      "12 d_loss: 1.6468840837478638 g_loss: 1.3847519159317017\n",
      "14 d_loss: 1.5709118843078613 g_loss: 1.1715478897094727\n",
      "16 d_loss: 1.8009024858474731 g_loss: 0.9301117062568665\n",
      "18 d_loss: 2.1934595108032227 g_loss: 0.7930712699890137\n",
      "20 d_loss: 1.3827064037322998 g_loss: 2.0372588634490967\n",
      "22 d_loss: 1.6147756576538086 g_loss: 1.2842316627502441\n",
      "24 d_loss: 2.168334484100342 g_loss: 2.344623327255249\n"
     ]
    }
   ],
   "source": [
    "main_stage2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
