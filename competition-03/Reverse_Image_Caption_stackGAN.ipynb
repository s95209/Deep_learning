{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_CUDNN_USE_AUTOTUNE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 22:39:52.865648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 22:39:54.347727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.347850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.352072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.352208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.352317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.352408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.353136: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 22:39:54.354110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.354236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.354329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.729689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.729818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.729913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 22:39:54.729987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 1024\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_CHANNEL = 3\n",
    "vocabulary_size = 0\n",
    "\n",
    "caption_embedding_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word2Id_dict), output_dim=EMBEDDING_DIM, input_length=20),\n",
    "])\n",
    "\n",
    "def training_data_generator(image_path, caption):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    caption = tf.cast(caption, tf.int32)\n",
    "    caption_embedding = caption_embedding_model(caption)\n",
    "    caption_embedding = tf.reduce_mean(caption_embedding, axis=0)\n",
    "    \n",
    "    return img, caption_embedding\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator):\n",
    "    # load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, caption))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_data_generator(caption, index):\n",
    "    caption = tf.cast(caption, tf.float32)\n",
    "    caption_embedding = caption_embedding_model(caption)\n",
    "    caption_embedding = tf.reduce_mean(caption_embedding, axis=0)\n",
    "    return caption, caption_embedding\n",
    "\n",
    "def testing_dataset_generator(batch_size, data_generator):\n",
    "    data = pd.read_pickle('./dataset/testData.pkl')\n",
    "    captions = data['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int)\n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_c(x):\n",
    "    mean = x[:,:128]\n",
    "    log_sigma = x[:,128:]\n",
    "    stddev = tf.exp(log_sigma)\n",
    "    epsilon = tf.random.normal((mean.shape[1],),dtype=tf.int32)\n",
    "    c = stddev * epsilon + mean\n",
    "    return c\n",
    "\n",
    "class CA(keras.Model):\n",
    "    \"\"\"\n",
    "    Get conditioning augmentation model.\n",
    "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CA,self).__init__()\n",
    "        self.fc = layers.Dense(256)\n",
    "        self.activation  = layers.LeakyReLU(alpha=0.2)\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.activation(self.fc(inputs))\n",
    "        return x\n",
    "\n",
    "class Embedding_Compressor(keras.Model):\n",
    "    \"\"\"\n",
    "    Build embedding compressor model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Embedding_Compressor,self).__init__()\n",
    "        self.fc = layers.Dense(128)\n",
    "        self.activation = layers.ReLU()\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.activation(self.fc(inputs))\n",
    "        return x\n",
    "\n",
    "class Generator_stage1(keras.Model):\n",
    "    \"\"\"\n",
    "    Builds a generator model used in Stage-I\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator_stage1,self).__init__()\n",
    "        self.ca_fc = layers.Dense(256)\n",
    "        self.ca_activation = layers.LeakyReLU(alpha=0.2)\n",
    "        #self.lambda1 = layers.Lambda(generator_c)\n",
    "        #self.mean1 = layers.Dense(128)\n",
    "        #self.log_sigma1 = layers.Dense(128)\n",
    "        self.fc1 = layers.Dense(128 * 8 * 4 * 4,use_bias=False)\n",
    "        self.activation = layers.ReLU()\n",
    "        \n",
    "        self.upsampling1 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv1 = layers.Conv2D(512,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac1 = layers.ReLU()\n",
    "        \n",
    "        self.upsampling2 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv2 = layers.Conv2D(256,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "\n",
    "        self.upsampling3 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv3 = layers.Conv2D(128,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.ReLU()\n",
    "\n",
    "        self.upsampling4 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv4 = layers.Conv2D(64,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.ReLU()\n",
    "\n",
    "        self.conv5 = layers.Conv2D(3,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        mean_logsigma = tf.split(self.ca_activation(self.ca_fc(inputs[0])),num_or_size_splits=2,axis=-1)\n",
    "        #print(mean_logsigma.shape)\n",
    "        #c = self.lambda1(mean_logsigma)\n",
    "        #mean_logsigma_split = tf.split(mean_logsigma,num_or_size_splits=2,axis=-1)\n",
    "        mean = mean_logsigma[0]\n",
    "        log_sigma = mean_logsigma[1]\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = stddev * inputs[2] + mean\n",
    "        #print(c.shape)\n",
    "        gen_inputs = tf.concat([c,inputs[1]],axis=1)\n",
    "        #print(gen_inputs.shape)\n",
    "        x = self.activation(self.fc1(gen_inputs))\n",
    "        #print(x.shape)\n",
    "        x = tf.reshape(x,shape=(-1,4,4,128*8))\n",
    "        x = self.ac1(self.bn1(self.conv1(self.upsampling1(x)),training=training))\n",
    "        x = self.ac2(self.bn2(self.conv2(self.upsampling2(x)),training=training))\n",
    "        x = self.ac3(self.bn3(self.conv3(self.upsampling3(x)),training=training))\n",
    "        x = self.ac4(self.bn4(self.conv4(self.upsampling4(x)),training=training))\n",
    "        x = self.conv5(x)\n",
    "        x = tf.tanh(x)\n",
    "        #print(x.shape)\n",
    "        return x,mean_logsigma\n",
    "\n",
    "class Discriminator_stage1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_stage1,self).__init__()\n",
    "        self.e_fc = layers.Dense(128)\n",
    "        self.e_ac = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.ac1 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv2 = layers.Conv2D(128,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv3 = layers.Conv2D(256,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(4,4),padding='same',strides=2,use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv5 = layers.Conv2D(512,kernel_size=1,padding='same',strides=1)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.ac1(self.conv1(inputs[0]))\n",
    "        #print(x.shape)\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.ac4(self.bn3(self.conv4(x),training=training))\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        input_layer2 = self.e_ac(self.e_fc(inputs[1]))\n",
    "        #print(input_layer2.shape)\n",
    "        input_layer2 = tf.reshape(input_layer2,shape=(-1,1,1,128))\n",
    "        #print(input_layer2.shape)\n",
    "        input_layer2 = tf.tile(input_layer2,[1,4,4,1])\n",
    "        #print(input_layer2.shape)\n",
    "        x = tf.concat([x,input_layer2],axis=-1)\n",
    "        #print(x.shape)\n",
    "        x = self.ac5(self.bn4(self.conv5(x),training=training))\n",
    "        #print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        #print(x.shape)\n",
    "        x = tf.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_block(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Residual_block,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(128*4,kernel_size=(3,3),padding='same',stride=1)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac1 = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(128*4,kernel_size=(3,3),padding='same',strides=1)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.bn1(self.conv1(inputs),training=training)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn2(self.conv2(x),training=training)\n",
    "        x = layers.add([x,inputs])\n",
    "        x = self.ac2(x)\n",
    "        return x\n",
    "\n",
    "class Generator_stage2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator_stage2,self).__init__()\n",
    "        self.ca_fc = layers.Dense(256)\n",
    "        self.ca_activation = layers.LeakyReLU(alpha=0.2)\n",
    "        #self.mean1 = layers.Dense(128)\n",
    "        #self.log_sigma1 = layers.Dense(128)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(128,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.ac1 = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(256,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.ReLU()\n",
    "        self.conv3 = layers.Conv2D(512,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.ReLU()\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.ReLU()\n",
    "\n",
    "        self.rb1 = Residual_block()\n",
    "        self.rb2 = Residual_block()\n",
    "        self.rb3 = Residual_block()\n",
    "        self.rb4 = Residual_block()\n",
    "        \n",
    "        self.upsampling1 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv5 = layers.Conv2D(512,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.ReLU()\n",
    "\n",
    "        self.upsampling2 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv6 = layers.Conv2D(256,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.ac6 = layers.ReLU()\n",
    "\n",
    "        self.upsampling3 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv7 = layers.Conv2D(128,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn6 = layers.BatchNormalization()\n",
    "        self.ac7 = layers.ReLU()\n",
    "\n",
    "        self.upsampling4 = layers.UpSampling2D(size=(2,2))\n",
    "        self.conv8 = layers.Conv2D(64,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "        self.bn7 = layers.BatchNormalization()\n",
    "        self.ac8 = layers.ReLU()\n",
    "\n",
    "        self.conv9 = layers.Conv2D(3,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    def call(self,inputs,training):\n",
    "        #CA Network\n",
    "        mean_logsigma = tf.split(self.ca_activation(self.ca_fc(inputs[0])),num_or_size_splits=2,axis=-1)\n",
    "        #mean_logsigma = self.ca_activation(self.ca_fc(inputs[0]))\n",
    "        mean = mean_logsigma[0]\n",
    "        log_sigma = mean_logsigma[1]\n",
    "        stddev = tf.exp(log_sigma)\n",
    "        c = stddev * inputs[2] + mean\n",
    "        #c = tf.concat([c,inputs[1]],axis=1)\n",
    "        #Image Encoder\n",
    "        x = self.ac1(self.conv1(inputs[1]))\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        c = tf.expand_dims(c,axis=1)\n",
    "        c = tf.expand_dims(c,axis=1)\n",
    "        c = tf.tile(c,[1,16,16,1])\n",
    "        #Concatenation\n",
    "        c_code = tf.concat([c,x],axis=3)\n",
    "        #Residual Block\n",
    "        x = self.ac4(self.bn3(self.conv4(c_code),training=training))\n",
    "        x = self.rb1(x)\n",
    "        x = self.rb2(x)\n",
    "        x = self.rb3(x)\n",
    "        x = self.rb4(x)\n",
    "        #Upsampling block\n",
    "        x = self.ac5(self.bn4(self.conv5(self.upsampling1(x)),training=training))\n",
    "        x = self.ac6(self.bn5(self.conv6(self.upsampling2(x)),training=training))\n",
    "        x = self.ac7(self.bn6(self.conv7(self.upsampling3(x)),training=training))\n",
    "        x = self.ac8(self.bn7(self.conv8(self.upsampling4(x)),training=training))\n",
    "        x = self.conv9(x)\n",
    "        x = tf.tanh(x)\n",
    "        return x,mean_logsigma\n",
    "\n",
    "class Discriminator_stage2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_stage2,self).__init__()\n",
    "        self.e_fc = layers.Dense(128)\n",
    "        self.e_ac = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.ac1 = layers.LeakyReLU(alpha=0.2)\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(128,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.ac2 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv3 = layers.Conv2D(256,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.ac3 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv4 = layers.Conv2D(512,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.ac4 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv5 = layers.Conv2D(1024,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.ac5 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv6 = layers.Conv2D(2048,kernel_size=(4,4),strides=2,padding='same',use_bias=False)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.ac6 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv7 = layers.Conv2D(1024,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn6 = layers.BatchNormalization()\n",
    "        self.ac7 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv8 = layers.Conv2D(512,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn7 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv9 = layers.Conv2D(128,kernel_size=(1,1),strides=1,padding='same',use_bias=False)\n",
    "        self.bn8 = layers.BatchNormalization()\n",
    "        self.ac8 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv10 = layers.Conv2D(128,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn9 = layers.BatchNormalization()\n",
    "        self.ac9 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv11 = layers.Conv2D(512,kernel_size=(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.bn10 = layers.BatchNormalization()\n",
    "\n",
    "        self.ac10 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.conv12 = layers.Conv2D(64*8,kernel_size=1,strides=1,padding='same')\n",
    "        self.bn11 = layers.BatchNormalization()\n",
    "        self.ac11 = layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = self.ac1(self.conv1(inputs[0]))\n",
    "        x = self.ac2(self.bn1(self.conv2(x),training=training))\n",
    "        x = self.ac3(self.bn2(self.conv3(x),training=training))\n",
    "        x = self.ac4(self.bn3(self.conv4(x),training=training))\n",
    "        x = self.ac5(self.bn4(self.conv5(x),training=training))\n",
    "        x = self.ac6(self.bn5(self.conv6(x),training=training))\n",
    "        x = self.ac7(self.bn6(self.conv7(x),training=training))\n",
    "        x = self.bn7(self.conv8(x))\n",
    "        \n",
    "        x2 = self.ac8(self.bn8(self.conv9(x),training=training))\n",
    "        x2 = self.ac9(self.bn9(self.conv10(x2),training=training))\n",
    "        x2 = self.bn10(self.conv11(x2))\n",
    "\n",
    "        added_x = layers.add([x,x2])\n",
    "        added_x = self.ac10(added_x)\n",
    "\n",
    "        input_layer2 = self.e_ac(self.e_fc(inputs[1]))\n",
    "        input_layer2 = tf.reshape(input_layer2,shape=(-1,1,1,128))\n",
    "        input_layer2 = tf.tile(input_layer2,[1,4,4,1])\n",
    "        x3 = tf.concat([added_x,input_layer2],axis=-1)\n",
    "\n",
    "        x3 = self.ac11(self.bn11(self.conv12(x3),training=training))\n",
    "        x3 = self.faltten(x3)\n",
    "        x3 = self.fc(x3)\n",
    "        x3 = tf.sigmoid(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celoss_zeros(logits):\n",
    "\t# 计算属于与标签为0的交叉熵，使用标签平滑\n",
    "    y = tf.ones_like(logits) * 0.1\n",
    "    loss = keras.losses.binary_crossentropy(y,logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def celoss_ones(logits):\n",
    "    # 计算属于与标签为1的交叉熵，使用标签平滑\n",
    "    y = tf.ones_like(logits) * 0.9\n",
    "    loss = keras.losses.binary_crossentropy(y, logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def KL_loss(logits):\n",
    "    mean = logits[0]\n",
    "    logsigma = logits[1]\n",
    "    loss = -logsigma + 0.5 * (-1 + tf.exp(2. * logsigma) + tf.square(mean))\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def d_loss_fn(batch_size,generator,discriminator,img_batch,embedding_batch,z_noise,condition_var,training):\n",
    "    # 采样生成图片\n",
    "    # print('======================================================')\n",
    "    # print(embedding_batch.shape)\n",
    "    fake_images,_ = generator([embedding_batch,z_noise,condition_var],training)\n",
    "    # print('======================================================')\n",
    "    # 判定生成图片\n",
    "    d_fake_logits = discriminator([fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    # 判定真实图片\n",
    "    d_real_logits = discriminator([img_batch,embedding_batch], training)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    # 判定不符嵌入\n",
    "    d_wrong_logits = discriminator([img_batch[:(batch_size-1)],embedding_batch[1:]],training)\n",
    "    d_loss_wrong = celoss_zeros(d_wrong_logits)\n",
    "    loss = d_loss_fake + d_loss_real + d_loss_wrong\n",
    "    return loss\n",
    "\n",
    "def g_loss_fn(generator,discriminator,embedding_batch,z_noise,condition_var,training):\n",
    "    fake_images,mean_logsigma = generator([embedding_batch,z_noise,condition_var],training)\n",
    "    d_fake_logits = discriminator([fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_ones(d_fake_logits)\n",
    "    d_KL_fake = KL_loss(mean_logsigma)\n",
    "    loss = d_loss_fake + 2.0 * d_KL_fake\n",
    "    return loss\n",
    "\n",
    "def d_loss_fn_stage2(batch_size=64,\n",
    "                     gen_stage1=None,\n",
    "                     gen_stage2=None,\n",
    "                     dis_stage2=None,\n",
    "                     image_batch=None,\n",
    "                     embedding_batch=None,\n",
    "                     z_noise=None,\n",
    "                     condition_var=None,\n",
    "                     training=False):\n",
    "    lr_fake_images,_ = gen_stage1([embedding_batch,z_noise,condition_var])\n",
    "    hr_fake_images,_ = gen_stage2([embedding_batch,lr_fake_images,condition_var],training)\n",
    "    # 判定生成图片\n",
    "    d_fake_logits = dis_stage2([hr_fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    # 判定真实图片\n",
    "    d_real_logits = dis_stage2([image_batch,embedding_batch], training)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    # 判定不符嵌入\n",
    "    d_wrong_logits = dis_stage2([image_batch[:(batch_size-1)],embedding_batch[1:]],training)\n",
    "    d_loss_wrong = celoss_zeros(d_wrong_logits)\n",
    "    loss = d_loss_fake + d_loss_real + d_loss_wrong\n",
    "    return loss\n",
    "\n",
    "def g_loss_fn_stage2(gen_stage1=None,\n",
    "                     gen_stage2=None,\n",
    "                     dis_stage2=None,\n",
    "                     embedding_batch=None,\n",
    "                     z_noise=None,\n",
    "                     condition_var=None,\n",
    "                     training=False):\n",
    "    lr_fake_images,_ = gen_stage1([embedding_batch,z_noise,condition_var])\n",
    "    hr_fake_images,mean_logsigma = gen_stage2([embedding_batch,lr_fake_images,condition_var],training)\n",
    "    d_fake_logits = dis_stage2([hr_fake_images,embedding_batch], training)\n",
    "    d_loss_fake = celoss_ones(d_fake_logits)\n",
    "    d_KL_fake = KL_loss(mean_logsigma)\n",
    "    loss = d_loss_fake + 2.0 * d_KL_fake\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片保存函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(val_out,val_block_size,image_path,color_mode):\n",
    "    def preprocessing(img):\n",
    "        img = ((img + 1.0)*(255./2)).astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocessed = preprocessing(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocessed[b,:,:,:]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row,preprocessed[b,:,:,:]),axis=1)\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image).save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "z = tf.random.normal([64,100])\n",
    "db_test = testing_dataset_generator(8, testing_data_generator)\n",
    "db_test = iter(db_test)\n",
    "caption ,embeddings_test = next(db_test)\n",
    "embeddings_test = np.repeat(embeddings_test, 8, axis=0)\n",
    "\n",
    "caption = caption.numpy()\n",
    "print('==================================================')\n",
    "for i, c in enumerate(caption):\n",
    "    s = \"\"\n",
    "    for id in c :\n",
    "        s_id = str(int(id))\n",
    "        s += id2word_dict[s_id] + \" \"\n",
    "    print(f'index: {i}   caption: {s}')\n",
    "\n",
    "print('==================================================')\n",
    "\n",
    "def main_stage1():\n",
    "    data_dir = \"./birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 64\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 10000\n",
    "    condition_dim = 128\n",
    "    training=True\n",
    "\n",
    "    d_optimizer = keras.optimizers.Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    g_optimizer = keras.optimizers.Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "\n",
    "    db_train = dataset_generator('./dataset/text2ImgData.pkl', batch_size, training_data_generator)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    gen = Generator_stage1()\n",
    "    gen.build([[4,1024],[4,100],[128]]) # [embedding_batch,z_noise,condition_var]\n",
    "    try:\n",
    "        gen.load_weights(\"stage1_gen.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    dis = Discriminator_stage1()\n",
    "    dis.build([[4,64,64,3],[4,1024]])\n",
    "    try:\n",
    "        dis.load_weights(\"stage1_dis.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    #real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    #fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "    for epoch in range(epochs):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for index,(x,embedding) in enumerate(db_train):\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn(batch_size,gen,dis,x,embedding,z_noise,condition_var,training)\n",
    "            grads = tape.gradient(d_loss,dis.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads,dis.trainable_variables))\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                g_loss = g_loss_fn(gen,dis,embedding,z_noise,condition_var,training)\n",
    "            grads = tape.gradient(g_loss,gen.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(grads,gen.trainable_variables))\n",
    "            # print(f'batch: {index}  // d_loss: {d_loss}  // g_loss: {g_loss}')\n",
    "        if epoch % 2 == 0:\n",
    "            print(epoch,'d_loss:',float(d_loss),'g_loss:',float(g_loss))\n",
    "            #可视化\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            fake_image,_ = gen([embeddings_test,z,condition_var],training=False)\n",
    "            img_path = r'testout/ganstage1-{}.png'.format(epoch)\n",
    "            save_result(fake_image.numpy(),8,img_path,color_mode='P')\n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "        if epoch % 5 == 0:\n",
    "            timestamp = int(time.time())\n",
    "            gen.save_weights(f\"./weight/stage1_gen_{epoch}_{timestamp}.h5\")\n",
    "            dis.save_weights(f\"./weight/stage1_dis_{epoch}_{timestamp}.h5\")\n",
    "\n",
    "def main_stage2():\n",
    "    data_dir = \"data/birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 256\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 10000\n",
    "    condition_dim = 128\n",
    "    training=True\n",
    "\n",
    "\n",
    "\n",
    "    d_optimizer = keras.optimizers.Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    g_optimizer = keras.optimizers.Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    #Load dataset\n",
    "    db_hr_train = dataset_generator('./dataset/text2ImgData.pkl', batch_size, training_data_generator)\n",
    "    \n",
    "\n",
    "    # db_hr_test = testing_dataset_generator(8, testing_data_generator)\n",
    "    # db_hr_test = iter(db_hr_test)\n",
    "    # embeddings_test = next(db_hr_test)\n",
    "    # embeddings_test = np.repeat(embeddings_test, 8, axis=0)\n",
    "    \n",
    "\n",
    "    gen_stage1 = Generator_stage1()\n",
    "    gen_stage1.build([[4,1024],[4,100],[128]])\n",
    "    try:\n",
    "        gen_stage1.load_weights(\"stage1_gen.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    gen_stage2 = Generator_stage2()\n",
    "    gen_stage2.build([[4,1024],[4,64,64,3],[128]])\n",
    "    try:\n",
    "        gen_stage2.load_weights(\"stage2_gen.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    dis_stage2 = Discriminator_stage2()\n",
    "    dis_stage2.build([[4,256,256,3],[4,1024]])\n",
    "    try:\n",
    "        dis_stage2.load_weights(\"stage2_dis.h5\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for index,(x,embedding) in enumerate(db_hr_train):\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss = d_loss_fn_stage2(batch_size=batch_size,\n",
    "                                          gen_stage1=gen_stage1,\n",
    "                                          gen_stage2=gen_stage2,\n",
    "                                          dis_stage2=dis_stage2,\n",
    "                                          image_batch=x,\n",
    "                                          embedding_batch=embedding,\n",
    "                                          z_noise=z_noise,\n",
    "                                          condition_var=condition_var,\n",
    "                                          training=training)\n",
    "            grads = tape.gradient(d_loss,dis_stage2.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads,dis_stage2.trainable_variables))\n",
    "            z_noise = tf.random.normal(shape=(batch_size,z_dim))\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            with tf.GradientTape() as tape:\n",
    "                g_loss = g_loss_fn_stage2(gen_stage1=gen_stage1,\n",
    "                                          gen_stage2=gen_stage2,\n",
    "                                          dis_stage2=dis_stage2,\n",
    "                                          embedding_batch=embedding,\n",
    "                                          z_noise=z_noise,\n",
    "                                          condition_var=condition_var,\n",
    "                                          training=training)\n",
    "            grads = tape.gradient(g_loss,gen_stage2.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(grads,gen_stage2.trainable_variables))\n",
    "            # print(f'batch: {index}  // d_loss: {d_loss}  // g_loss: {g_loss}')\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch,'d_loss:',float(d_loss),'g_loss:',float(g_loss))\n",
    "            #可视化\n",
    "            condition_var = tf.random.normal(shape=(condition_dim,))\n",
    "            lr_fake_image,_ = gen_stage1([embeddings_test,z,condition_var],training=False)\n",
    "            hr_fake_image,_ = gen_stage2([embeddings_test,lr_fake_image,condition_var],training=False)\n",
    "            img_path = r'testout/ganstage2-{}.png'.format(epoch)\n",
    "            save_result(hr_fake_image.numpy(),8,img_path,color_mode='P')\n",
    "            d_losses.append(float(d_loss))\n",
    "            g_losses.append(float(g_loss))\n",
    "        if epoch % 5 == 0:\n",
    "            timestamp = int(time.time())\n",
    "            gen_stage2.save_weights(f\"./weight/stage2_gen_{epoch}_{timestamp}.h5\")\n",
    "            dis_stage2.save_weights(f\"./weight/stage2_dis_{epoch}_{timestamp}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_stage2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
