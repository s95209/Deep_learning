{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Lab13: GAN<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "111062697 吳律穎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the Improved WGAN.\n",
    "2. Train the Improved WGAN on CelebA dataset. Build dataset that read and resize images to 64 x 64 for training.\n",
    "3. Show a gif of generated samples (at least 8 x 8) to demonstrate the training process and show the best generated sample(s). Please upload to your Google drive and share the link.\n",
    "4. Draw the loss curve of discriminator and generator during training process into one image.\n",
    "5. Write a brief report about what you have done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warnings and info\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import imageio\n",
    "import moviepy.editor as mpy\n",
    "import glob\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "SAMPLE_COL = 8\n",
    "SAMPLE_ROW = 8\n",
    "SAMPLE_NUM = SAMPLE_COL * SAMPLE_ROW\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "IMG_SHAPE = (IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "Z_DIM = 128\n",
    "BUF = 65536\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCH = 256\n",
    "\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "LAMBDA = 10\n",
    "\n",
    "IMG_DIR = './imgs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utPuzzle(imgs, row, col, path=None):\n",
    "    h, w, c = imgs[0].shape\n",
    "    out = np.zeros((h * row, w * col, c), np.uint8)\n",
    "    for n, img in enumerate(imgs):\n",
    "        j, i = divmod(n, col)\n",
    "        out[j * h : (j + 1) * h, i * w : (i + 1) * w, :] = img\n",
    "    if path is not None : imageio.imwrite(path, out)\n",
    "    return out\n",
    "  \n",
    "def utMakeGif(imgs, fname, duration):\n",
    "    n = float(len(imgs)) / duration\n",
    "    clip = mpy.VideoClip(lambda t : imgs[int(n * t)], duration = duration)\n",
    "    clip.write_gif(fname, fps = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_C)\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "img_name = glob.glob('./dataset/img_align_celeba_png/*.png')\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(img_name)\\\n",
    "                               .map(map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "                               .shuffle(BUF)\\\n",
    "                               .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "                               .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(img_shape, z_dim):\n",
    "    # x-shape\n",
    "    xh, xw, xc = img_shape\n",
    "    # z-shape\n",
    "    zh = xh // 4\n",
    "    zw = xw // 4\n",
    "        \n",
    "    # return Generator and Discriminator\n",
    "    return keras.Sequential([ # Generator\n",
    "        keras.layers.Dense(units  =  1024, input_shape = (z_dim,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(units  =  zh * zw << 8), # zh * zw * 256\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Reshape(target_shape = (zh, zw, 256)),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.sigmoid\n",
    "        ),\n",
    "    ]), keras.Sequential([ # Discriminator\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = img_shape,\n",
    "        ),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units  =  1024),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dense(units  =  1),\n",
    "    ])\n",
    "\n",
    "s = tf.random.normal([SAMPLE_NUM, Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen, Dis = GAN(IMG_SHAPE, Z_DIM)\n",
    "optimizer_g = keras.optimizers.Adam(LR, beta1, beta2)\n",
    "optimizer_d = keras.optimizers.Adam(LR, beta1, beta2)\n",
    "\n",
    "@tf.function\n",
    "def G_train_step(c1):\n",
    "    z = tf.random.normal([BATCH_SIZE, Z_DIM])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        c0 = Gen(z, training=True)\n",
    "\n",
    "        z0 = Dis(c0, training=True)\n",
    "        z1 = Dis(c1, training=True)\n",
    "\n",
    "        lg = tf.reduce_mean(-z0)\n",
    "\n",
    "        epsilon = tf.random.uniform([BATCH_SIZE, 1, 1, 1])\n",
    "        x_hat = epsilon * c1 + (1 - epsilon) * c0\n",
    "        gradient_x_hat = tf.gradients(Dis(x_hat, training=True), x_hat)[0]\n",
    "        l2_norm = (tf.sqrt(tf.reduce_sum(gradient_x_hat ** 2, axis=[1, 2, 3])) - 1.) ** 2\n",
    "        ld = tf.reduce_mean(z0 - z1 + LAMBDA * l2_norm)\n",
    "\n",
    "    gradient_g = tape.gradient(lg, Gen.trainable_variables)\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, Gen.trainable_variables))\n",
    "\n",
    "    return lg, ld\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def D_train_step(c1):\n",
    "    z = tf.random.normal([BATCH_SIZE, Z_DIM])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        c0 = Gen(z, training=True)\n",
    "\n",
    "        z0 = Dis(c0, training=True)\n",
    "        z1 = Dis(c1, training=True)\n",
    "\n",
    "        lg = tf.reduce_mean(-z0)\n",
    "\n",
    "        epsilon = tf.random.uniform([BATCH_SIZE, 1, 1, 1])\n",
    "        x_hat = epsilon * c1 + (1 - epsilon) * c0\n",
    "        gradient_x_hat = tf.gradients(Dis(x_hat, training=True), x_hat)[0]\n",
    "        l2_norm = (tf.sqrt(tf.reduce_sum(gradient_x_hat ** 2, axis=[1, 2, 3])) - 1.) ** 2\n",
    "        ld = tf.reduce_mean(z0 - z1 + LAMBDA * l2_norm)\n",
    "\n",
    "    gradient_d = tape.gradient(ld, Dis.trainable_variables)\n",
    "    optimizer_d.apply_gradients(zip(gradient_d, Dis.trainable_variables))\n",
    "\n",
    "    return lg, ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = (\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    G_train_step\n",
    ")\n",
    "\n",
    "num_critic = len(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_list = [None] * EPOCH\n",
    "dl_list = [None] * EPOCH\n",
    "sample_list = [None] * EPOCH  \n",
    "\n",
    "sample_z = tf.random.normal([SAMPLE_NUM, Z_DIM])\n",
    "\n",
    "ctr = 0\n",
    "rsTrain = float(BATCH_SIZE) / float(len(img_name))\n",
    "\n",
    "for ep in range(EPOCH):\n",
    "    loss_g_t = 0.0\n",
    "    loss_d_t = 0.0\n",
    "    for batch in dataset_train:\n",
    "        loss_g, loss_d = train_step[ctr](batch)\n",
    "        ctr += 1\n",
    "        loss_g_t += loss_g.numpy()\n",
    "        loss_d_t += loss_d.numpy()\n",
    "        if ctr == num_critic : ctr = 0\n",
    "    gl_list[ep] = loss_g_t * rsTrain\n",
    "    dl_list[ep] = loss_d_t * rsTrain\n",
    "\n",
    "    out = Gen(sample_z, training=False)\n",
    "\n",
    "    img = utPuzzle(\n",
    "        (out * 255.0).numpy().astype(np.uint8),\n",
    "        SAMPLE_COL,\n",
    "        SAMPLE_ROW,\n",
    "        \"imgs/w_improved_%04d.png\" % ep\n",
    "    )\n",
    "    sample_list[ep] = img\n",
    "\n",
    "    if (ep + 1) % 32 == 0:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Epoch {ep:d}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utMakeGif(np.array(sample_list), \"imgs/w_improved_gan.gif\", duration=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(EPOCH), dl_list, color = \"blue\", label = \"Discriminator Loss\")\n",
    "plt.plot(range(EPOCH), gl_list, color = \"red\",  label = \"Generator Loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"DCGAN Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss 是依照 Lab13 notebook 給的 pseudo code 來更改助教 loss 的訂法， hyperparameter 也是依照 pseudo code 上方給的數值來賦值。 而 model architecture 則是直接用 lab13 notebook 中給的架構，並依照 paper 將所有 batch Normalization 都移除。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
