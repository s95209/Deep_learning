{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Lab13: GAN<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "111062697 吳律穎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the Improved WGAN.\n",
    "2. Train the Improved WGAN on CelebA dataset. Build dataset that read and resize images to 64 x 64 for training.\n",
    "3. Show a gif of generated samples (at least 8 x 8) to demonstrate the training process and show the best generated sample(s). Please upload to your Google drive and share the link.\n",
    "4. Draw the loss curve of discriminator and generator during training process into one image.\n",
    "5. Write a brief report about what you have done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warnings and info\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import imageio\n",
    "import moviepy.editor as mpy\n",
    "import glob\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "SAMPLE_COL = 8\n",
    "SAMPLE_ROW = 8\n",
    "SAMPLE_NUM = SAMPLE_COL * SAMPLE_ROW\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "IMG_SHAPE = (IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "Z_DIM = 128\n",
    "BUF = 65536\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCH = 256\n",
    "\n",
    "BETA_1 = 0\n",
    "BETA_2 = 0.9\n",
    "LAMBDA = 10\n",
    "\n",
    "IMG_DIR = './imgs/'\n",
    "if not os.path.exists(IMG_DIR):\n",
    "    os.makedirs(IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utPuzzle(imgs, row, col, path=None):\n",
    "    h, w, c = imgs[0].shape\n",
    "    out = np.zeros((h * row, w * col, c), np.uint8)\n",
    "    for n, img in enumerate(imgs):\n",
    "        j, i = divmod(n, col)\n",
    "        out[j * h : (j + 1) * h, i * w : (i + 1) * w, :] = img\n",
    "    if path is not None : imageio.imwrite(path, out)\n",
    "    return out\n",
    "  \n",
    "def utMakeGif(imgs, fname, duration):\n",
    "    n = float(len(imgs)) / duration\n",
    "    clip = mpy.VideoClip(lambda t : imgs[int(n * t)], duration = duration)\n",
    "    clip.write_gif(fname, fps = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_C)\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "img_name_list = sorted(glob.glob('./dataset/img_align_celeba_png/*.png'))\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(img_name_list)\\\n",
    "                               .map(map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "                               .shuffle(BUF)\\\n",
    "                               .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "                               .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(img_shape, z_dim):\n",
    "    # x-shape\n",
    "    xh, xw, xc = img_shape\n",
    "    # z-shape\n",
    "    zh = xh // 4\n",
    "    zw = xw // 4\n",
    "        \n",
    "    # return Generator and Discriminator\n",
    "    return keras.Sequential([ # Generator\n",
    "        keras.layers.Dense(units  =  1024, input_shape = (z_dim,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(units  =  zh * zw << 8), # zh * zw * 256\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Reshape(target_shape = (zh, zw, 256)),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.sigmoid\n",
    "        ),\n",
    "    ]), keras.Sequential([ # Discriminator\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = img_shape,\n",
    "        ),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units  =  1024),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dense(units  =  1),\n",
    "    ])\n",
    "\n",
    "s = tf.random.normal([SAMPLE_NUM, Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, D = GAN(IMG_SHAPE, Z_DIM)\n",
    "optimizer_g = keras.optimizers.Adam(LR, BETA_1, BETA_2)\n",
    "optimizer_d = keras.optimizers.Adam(LR, BETA_1, BETA_2)\n",
    "\n",
    "@tf.function\n",
    "def G_train_step(real_data):\n",
    "    z = tf.random.normal([BATCH_SIZE, Z_DIM])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_data = G(z, training=True)\n",
    "\n",
    "        D_f = D(fake_data, training=True)\n",
    "        D_r = D(real_data, training=True)\n",
    "\n",
    "        loss_g = tf.reduce_mean(-D_f)\n",
    "\n",
    "        epsilon = tf.random.uniform([BATCH_SIZE, 1, 1, 1])\n",
    "        x_hat = epsilon * real_data + (1 - epsilon) * fake_data\n",
    "        gradient_x_hat = tf.gradients(D(x_hat, training=True), x_hat)[0]\n",
    "        l2_norm = (tf.sqrt(tf.reduce_sum(gradient_x_hat ** 2, axis=[1, 2, 3])) - 1.) ** 2\n",
    "        loss_d = tf.reduce_mean(D_f - D_r + LAMBDA * l2_norm)\n",
    "\n",
    "    gradient_g = tape.gradient(loss_g, G.trainable_variables)\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, G.trainable_variables))\n",
    "\n",
    "    return loss_g, loss_d\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def D_train_step(real_data):\n",
    "    z = tf.random.normal([BATCH_SIZE, Z_DIM])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_data = G(z, training=True)\n",
    "\n",
    "        D_f = D(fake_data, training=True)\n",
    "        D_r = D(real_data, training=True)\n",
    "\n",
    "        loss_g = tf.reduce_mean(-D_f)\n",
    "\n",
    "        epsilon = tf.random.uniform([BATCH_SIZE, 1, 1, 1])\n",
    "        x_hat = epsilon * real_data + (1 - epsilon) * fake_data\n",
    "        gradient_x_hat = tf.gradients(D(x_hat, training=True), x_hat)[0]\n",
    "        l2_norm = (tf.sqrt(tf.reduce_sum(gradient_x_hat ** 2, axis=[1, 2, 3])) - 1.) ** 2\n",
    "        \n",
    "        loss_d = tf.reduce_mean(D_f - D_r + LAMBDA * l2_norm)\n",
    "\n",
    "    gradient_d = tape.gradient(loss_d, D.trainable_variables)\n",
    "    optimizer_d.apply_gradients(zip(gradient_d, D.trainable_variables))\n",
    "\n",
    "    return loss_g, loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = (\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    D_train_step,\n",
    "    G_train_step\n",
    ")\n",
    "\n",
    "num_critic = len(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_list = [None] * EPOCH  # record loss of g for each epoch\n",
    "d_loss_list = [None] * EPOCH  # record loss of d for each epoch\n",
    "sample_list = [None] * EPOCH  # record sample images for each epoch\n",
    "\n",
    "sample_z = tf.random.normal([SAMPLE_NUM, Z_DIM])\n",
    "\n",
    "critic = 0\n",
    "STEP = len(img_name_list) // BATCH_SIZE\n",
    "\n",
    "pbar = trange(EPOCH, unit='epoch')\n",
    "for epoch in pbar:\n",
    "    loss_g_t = 0.0\n",
    "    loss_d_t = 0.0\n",
    "    for real_data in dataset_train:\n",
    "        loss_g, loss_d = train_step[critic](real_data)\n",
    "        critic = critic + 1 if critic + 1 < num_critic else 0\n",
    "        loss_g_t += loss_g.numpy()\n",
    "        loss_d_t += loss_d.numpy()\n",
    "\n",
    "    g_loss_list[epoch] = loss_g_t / STEP\n",
    "    d_loss_list[epoch] = loss_d_t / STEP\n",
    "    pbar.set_postfix({'g_loss': loss_g_t / STEP, 'd_loss': loss_d_t / STEP})\n",
    "\n",
    "    out = G(sample_z, training=False)\n",
    "    img = utPuzzle(\n",
    "        (out * 255.0).numpy().astype(np.uint8),\n",
    "        SAMPLE_COL,\n",
    "        SAMPLE_ROW,\n",
    "        f'{IMG_DIR}WGAN-Improved_{epoch:04d}.png'\n",
    "    )\n",
    "    sample_list[epoch] = img\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Epoch {epoch:d}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utMakeGif(np.array(sample_list), f'{IMG_DIR}WGAN-Improved.gif', duration=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(EPOCH), g_loss_list, color='red', label='Generator Loss')\n",
    "plt.plot(range(EPOCH), d_loss_list, color='blue', label='Discriminator Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('WGAN-Improved Training Loss')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_DIR}WGAN-Improved_Training_Loss.png', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss 是依照 Lab13 notebook 給的 pseudo code 來更改助教 loss 的訂法， hyperparameter 也是依照 pseudo code 上方給的數值來賦值。 而 model architecture 則是直接用 lab13 notebook 中給的架構。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
