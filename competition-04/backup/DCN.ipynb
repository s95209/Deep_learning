{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:41:29.060871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:42:09.585468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:09.595966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.240797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.240958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.241059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.241154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.298405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 00:42:10.299465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.299671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:10.299770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:13.505111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:13.505253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:13.505352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 00:42:13.505442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成虛擬數據作為示例\n",
    "num_samples = 10000\n",
    "num_items = 20000\n",
    "user_ids = np.random.randint(1, 1000, size=num_samples)\n",
    "item_ids = np.random.randint(1, num_items, size=num_samples)\n",
    "labels = np.random.choice([0, 1], size=(num_samples, num_items), p=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數據劃分為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.column_stack((user_ids, item_ids)),\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCrossNetwork(tf.keras.Model):\n",
    "    def __init__(self, input_dim, embedding_dim, cross_layer_num, hidden_units, num_items):\n",
    "        super(DeepCrossNetwork, self).__init__()\n",
    "\n",
    "        self.embedding_layer = Embedding(input_dim=input_dim, output_dim=embedding_dim)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.deep_layers = [Dense(units, activation='relu') for units in hidden_units]\n",
    "        self.cross_layers = [self.cross_layer for _ in range(cross_layer_num)]\n",
    "\n",
    "        self.concatenate = Concatenate()\n",
    "        self.output_layer = Dense(num_items, activation='sigmoid')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_ids, item_ids = inputs\n",
    "\n",
    "        embedding_user = self.embedding_layer(user_ids)\n",
    "        embedding_item = self.embedding_layer(item_ids)\n",
    "\n",
    "        flat_embedding_user = self.flatten(embedding_user)\n",
    "        flat_embedding_item = self.flatten(embedding_item)\n",
    "\n",
    "        deep_output = flat_embedding_user\n",
    "        for layer in self.deep_layers:\n",
    "            deep_output = layer(deep_output)\n",
    "\n",
    "        cross_output = flat_embedding_user\n",
    "        for layer in self.cross_layers:\n",
    "            cross_output = layer(cross_output, flat_embedding_item)\n",
    "\n",
    "        combined_output = self.concatenate([deep_output, cross_output])\n",
    "        output = self.output_layer(combined_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def cross_layer(self, x0, x):\n",
    "        cross = tf.keras.layers.Dot(axes=1)([x, x0])\n",
    "        return x + cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_cross_network_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     multiple                  32        \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  1088      \n",
      "                                                                 \n",
      " dense_18 (Dense)            multiple                  2080      \n",
      "                                                                 \n",
      " concatenate_5 (Concatenate)  multiple                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            multiple                  980000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 983,200\n",
      "Trainable params: 983,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.0028 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6932 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6268315040>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_items = 20000  # Adjust based on your dataset\n",
    "input_dim = 2  # Adjust based on your dataset\n",
    "embedding_dim = 16\n",
    "cross_layer_num = 3\n",
    "hidden_units = [64, 32]\n",
    "\n",
    "model = DeepCrossNetwork(input_dim, embedding_dim, cross_layer_num, hidden_units, num_items)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "dummy_input = [tf.constant([[1], [2]]), tf.constant([[3], [4]])]  # Replace with actual data\n",
    "model(dummy_input)\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_train[:, 0], X_train[:, 1]], y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-GPU-Eric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
