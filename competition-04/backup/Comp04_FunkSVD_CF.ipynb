{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 4: Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment\n",
    "from queue import Queue\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5\n",
    "\n",
    "\n",
    "# parameters\n",
    "MODEL_PATH = \"./model\"\n",
    "CKP_DIR = \"./checkpoints/FunkSVD_CF_emb256_lr1e-4\"\n",
    "\n",
    "# FunkSVD hyperparameters\n",
    "EMBEDDING_SIZE = 256\n",
    "BATCH_SIZE = 128\n",
    "INITIAL_N_EPOCHS = 100\n",
    "N_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_EPISODES = 500\n",
    "\n",
    "\n",
    "# Q-learning\n",
    "# agent\n",
    "MIN_EXPLORING_RATE = 0.01\n",
    "MIN_LEARNING_RATE = 0.5\n",
    "\n",
    "# training\n",
    "NUM_EPISODE = 40000\n",
    "PRINT_EVERY_EPISODE = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "USER_ITEM_SIMILARITY = os.path.join('dataset', 'user_item_similarity.pkl')\n",
    "INTERACT_DATA = os.path.join('dataset', 'organized_interact_data.pkl')\n",
    "USER_RECOMMENDATION = os.path.join('dataset', 'user_recommendation_sim_based.pkl')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \n",
       "0       Health experts said it is too early to predict...  \n",
       "1       He was subdued by passengers and crew when he ...  \n",
       "2       \"Until you have a dog you don't understand wha...  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  \n",
       "...                                                   ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...  \n",
       "209525  CORRECTION: An earlier version of this story i...  \n",
       "209526  The five-time all-star center tore into his te...  \n",
       "\n",
       "[209527 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221764</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1     0.221764  0.055316  0.112049  0.190925  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_item_sim = pd.read_pickle(USER_ITEM_SIMILARITY)\n",
    "df_user_item_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12126</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9810</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9102</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>15075</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>64266</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795551</th>\n",
       "      <td>999</td>\n",
       "      <td>202879</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795759</th>\n",
       "      <td>999</td>\n",
       "      <td>175578</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795765</th>\n",
       "      <td>999</td>\n",
       "      <td>166140</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795821</th>\n",
       "      <td>999</td>\n",
       "      <td>153337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796155</th>\n",
       "      <td>999</td>\n",
       "      <td>150333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12791 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "0             0    12126       5\n",
       "1             0     9810       5\n",
       "4             0     9102       5\n",
       "8             0    15075       5\n",
       "101           0    64266       5\n",
       "...         ...      ...     ...\n",
       "795551      999   202879       5\n",
       "795759      999   175578       5\n",
       "795765      999   166140       5\n",
       "795821      999   153337       5\n",
       "796155      999   150333       5\n",
       "\n",
       "[12791 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interact_data = pd.read_pickle(INTERACT_DATA)\n",
    "df_interact_data[df_interact_data[\"rating\"] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunkSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVDRecommender(tf.keras.Model):\n",
    "    '''\n",
    "    Simplified Funk-SVD recommender model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, m_users: int, n_items: int, embedding_size: int, learning_rate: float, bias_mu):\n",
    "        '''\n",
    "        Constructor of the model\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.m = m_users\n",
    "        self.n = n_items\n",
    "        self.k = embedding_size\n",
    "        self.lr = learning_rate\n",
    "        self.B_mu = tf.constant([bias_mu])\n",
    "\n",
    "\n",
    "        # user embeddings P\n",
    "        self.P = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.m, self.k)))\n",
    "\n",
    "        # item embeddings Q\n",
    "        self.Q = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.n, self.k)))\n",
    "\n",
    "        # bias term\n",
    "        self.B_user = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.m, 1)))\n",
    "        self.B_item = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.n, 1)))\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, user_ids: tf.Tensor, item_ids: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Forward pass used in training and validating\n",
    "        '''\n",
    "        # dot product the user and item embeddings corresponding to the observed interaction pairs to produce predictions\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, indices=user_ids) * tf.gather(self.Q, indices=item_ids), axis=1)\n",
    "        y_pred = tf.add(y_pred, tf.squeeze(tf.gather(self.B_user, indices=user_ids)))\n",
    "        y_pred = tf.add(y_pred, tf.squeeze(tf.gather(self.B_item, indices=item_ids)))\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Compute the MSE loss of the model\n",
    "        '''\n",
    "        loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Train the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format [UserID, MovieID, Rating, Timestamp]\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # compute loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(user_ids, item_ids)\n",
    "            loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(self, data: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Validate the model with one batch\n",
    "        data: batched user-item interactions\n",
    "        each record in data is in the format [UserID, MovieID, Rating, Timestamp]\n",
    "        '''\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        # compute loss\n",
    "        y_pred = self(user_ids, item_ids)\n",
    "        loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def eval_predict_onestep(self, user_identity: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Retrieve and return the MovieIDs of the 10 recommended movies given a query\n",
    "        You should return a tf.Tensor with shape=(10,)\n",
    "        query will be a tf.Tensor with shape=(2,) and dtype=tf.int64\n",
    "        query[0] is the UserID of the query\n",
    "        query[1] is the Timestamp of the query\n",
    "        '''\n",
    "        # dot product the selected user and all item embeddings to produce predictions\n",
    "        user_id = tf.cast(user_identity, tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1)\n",
    "        # print(f\"y_pred: {y_pred.shape}\")\n",
    "\n",
    "        # select the top 5 items with highest scores in y_pred\n",
    "        y_top_5 = tf.math.top_k(y_pred, k=5).indices\n",
    "\n",
    "        return y_top_5\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def eval_predict_onestep_env(self, user_identity: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Retrieve and return the MovieIDs of the 10 recommended movies given a query\n",
    "        You should return a tf.Tensor with shape=(10,)\n",
    "        query will be a tf.Tensor with shape=(2,) and dtype=tf.int64\n",
    "        query[0] is the UserID of the query\n",
    "        query[1] is the Timestamp of the query\n",
    "        '''\n",
    "        # dot product the selected user and all item embeddings to produce predictions\n",
    "        user_id = tf.cast(user_identity, tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1)\n",
    "\n",
    "        y_pred_values, y_pred_indices = tf.math.top_k(y_pred, k=2000)\n",
    "        # sorted_indices = tf.argsort(y_pred, direction='DESCENDING')\n",
    "        # sorted_y_pred = tf.gather(y_pred, sorted_indices)\n",
    "\n",
    "        return y_pred_values, y_pred_indices\n",
    "    \n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        checkpoint = tf.train.Checkpoint(model=self)\n",
    "        checkpoint.save(os.path.join(save_path, 'funk_svd_recommender_weights'))    \n",
    "\n",
    "\n",
    "    def load_model(self, save_path):\n",
    "        checkpoint = tf.train.Checkpoint(model=self)\n",
    "        checkpoint.restore(tf.train.latest_checkpoint(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FunkSVD Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_info = {uid: {} for uid in range(N_TRAIN_USERS)}  # for every element: {user_id: {item_id: click_count}}\n",
    "\n",
    "with open('./dataset/clicked_ids_output_final.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().split(', ')\n",
    "        user_id = int(line[0])\n",
    "        item_id = int(line[1])\n",
    "        \n",
    "        try:\n",
    "            user_item_info[user_id][item_id] += 1\n",
    "        except KeyError:\n",
    "            user_item_info[user_id][item_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43856</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>63226</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>119480</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16929</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>187378</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137503</th>\n",
       "      <td>999</td>\n",
       "      <td>175254</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137504</th>\n",
       "      <td>999</td>\n",
       "      <td>183135</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137505</th>\n",
       "      <td>999</td>\n",
       "      <td>165246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137506</th>\n",
       "      <td>999</td>\n",
       "      <td>171658</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137507</th>\n",
       "      <td>999</td>\n",
       "      <td>136925</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0              0    43856       5\n",
       "1              0    63226       5\n",
       "2              0   119480       5\n",
       "3              0    16929       5\n",
       "4              0   187378       5\n",
       "...          ...      ...     ...\n",
       "2137503      999   175254       5\n",
       "2137504      999   183135       5\n",
       "2137505      999   165246       5\n",
       "2137506      999   171658       5\n",
       "2137507      999   136925       5\n",
       "\n",
       "[2137508 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for user_id in range(N_TRAIN_USERS):\n",
    "    for item_id in list(user_item_info[user_id].keys()):\n",
    "        temp.append([user_id, item_id, 5])\n",
    "\n",
    "\n",
    "df_interact = pd.DataFrame(temp, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>146057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>195688</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1998</td>\n",
       "      <td>60372</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1998</td>\n",
       "      <td>51442</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>1999</td>\n",
       "      <td>125409</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1999</td>\n",
       "      <td>77906</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1999</td>\n",
       "      <td>124792</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0           0    42558       5\n",
       "1           0    65272       5\n",
       "2           0    13353       5\n",
       "3           1   146057       5\n",
       "4           1   195688       5\n",
       "...       ...      ...     ...\n",
       "5995     1998    60372       5\n",
       "5996     1998    51442       5\n",
       "5997     1999   125409       5\n",
       "5998     1999    77906       5\n",
       "5999     1999   124792       5\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for i in range(N_TEST_USERS):\n",
    "    for item in df_user.iloc[i][\"history\"]:\n",
    "        temp.append([df_user[\"user_id\"][i], item, 5])\n",
    "\n",
    "df_exist = pd.DataFrame(temp, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>146057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>195688</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143503</th>\n",
       "      <td>999</td>\n",
       "      <td>175254</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143504</th>\n",
       "      <td>999</td>\n",
       "      <td>183135</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143505</th>\n",
       "      <td>999</td>\n",
       "      <td>165246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143506</th>\n",
       "      <td>999</td>\n",
       "      <td>171658</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143507</th>\n",
       "      <td>999</td>\n",
       "      <td>136925</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0              0    42558       5\n",
       "1              0    65272       5\n",
       "2              0    13353       5\n",
       "3              1   146057       5\n",
       "4              1   195688       5\n",
       "...          ...      ...     ...\n",
       "2143503      999   175254       5\n",
       "2143504      999   183135       5\n",
       "2143505      999   165246       5\n",
       "2143506      999   171658       5\n",
       "2143507      999   136925       5\n",
       "\n",
       "[2143508 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.concat([df_exist, df_interact], axis=0, ignore_index=True)\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 698.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataframes = []\n",
    "val_dataframes = []\n",
    "\n",
    "for i in tqdm(range(N_TEST_USERS)):\n",
    "    user_all = df_ratings[df_ratings['user_id'] == i]\n",
    "    user_train = user_all.iloc[3:]\n",
    "    user_val = user_all.iloc[:3]\n",
    "    # assert len(user_train) == 100\n",
    "    assert len(user_val) == 3\n",
    "    train_dataframes.append(user_train)\n",
    "    val_dataframes.append(user_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>63226</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>119480</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>187378</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137503</th>\n",
       "      <td>999</td>\n",
       "      <td>175254</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137504</th>\n",
       "      <td>999</td>\n",
       "      <td>183135</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137505</th>\n",
       "      <td>999</td>\n",
       "      <td>165246</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137506</th>\n",
       "      <td>999</td>\n",
       "      <td>171658</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137507</th>\n",
       "      <td>999</td>\n",
       "      <td>136925</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0              0    43856     1.0\n",
       "1              0    63226     1.0\n",
       "2              0   119480     1.0\n",
       "3              0    16929     1.0\n",
       "4              0   187378     1.0\n",
       "...          ...      ...     ...\n",
       "2137503      999   175254     1.0\n",
       "2137504      999   183135     1.0\n",
       "2137505      999   165246     1.0\n",
       "2137506      999   171658     1.0\n",
       "2137507      999   136925     1.0\n",
       "\n",
       "[2137508 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all per-user training sets\n",
    "df_train = pd.concat(train_dataframes, ignore_index=True)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "df_train_norm = df_train.copy(deep=True)\n",
    "df_train_norm['rating'] -= 3\n",
    "df_train_norm['rating'] /= 2\n",
    "df_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_mu =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get bias_mu\n",
    "BIAS_MU = df_train_norm['rating'].mean()\n",
    "print('bias_mu = ', BIAS_MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>146057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>195688</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1998</td>\n",
       "      <td>60372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1998</td>\n",
       "      <td>51442</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>1999</td>\n",
       "      <td>125409</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1999</td>\n",
       "      <td>77906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1999</td>\n",
       "      <td>124792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0           0    42558     1.0\n",
       "1           0    65272     1.0\n",
       "2           0    13353     1.0\n",
       "3           1   146057     1.0\n",
       "4           1   195688     1.0\n",
       "...       ...      ...     ...\n",
       "5995     1998    60372     1.0\n",
       "5996     1998    51442     1.0\n",
       "5997     1999   125409     1.0\n",
       "5998     1999    77906     1.0\n",
       "5999     1999   124792     1.0\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all per-user validation sets\n",
    "df_val = pd.concat(val_dataframes, ignore_index=True)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "# here we make a copy of the un-normalized validation set for evaluation\n",
    "df_val_norm = df_val.copy(deep=True)\n",
    "df_val_norm['rating'] -= 3\n",
    "df_val_norm['rating'] /= 2\n",
    "df_val_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_train_norm)\n",
    "dataset_train = dataset_train.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                             .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(df_val_norm)\n",
    "dataset_val = dataset_val.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                         .prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log2(x: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.math.log(tf.cast(x, tf.float32)) / tf.math.log(2.)\n",
    "\n",
    "@tf.function\n",
    "def ndcg_at_5(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    y_pred = y_pred[:5]\n",
    "    idx = tf.equal(tf.cast(y_pred, tf.int32), tf.cast(y_true, tf.int32))\n",
    "    if tf.reduce_sum(tf.cast(idx, tf.int32)) > 0:\n",
    "        return 1. / log2(2 + tf.argmax(idx))\n",
    "    else:\n",
    "        return tf.constant(0.)\n",
    "\n",
    "@tf.function\n",
    "def recall_at_5(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    y_pred = y_pred[:5]\n",
    "    idx = tf.equal(tf.cast(y_pred, tf.int32), tf.cast(y_true, tf.int32))\n",
    "    if tf.reduce_sum(tf.cast(idx, tf.int32)) > 0:\n",
    "        return tf.constant(1.)\n",
    "    else:\n",
    "        return tf.constant(0.)\n",
    "\n",
    "def evaluate(model: tf.keras.Model, dataset: tf.data.Dataset) -> tuple:\n",
    "    '''\n",
    "    For each data point in the dataset:\n",
    "    data[0] is the UserID\n",
    "    data[1] is the ItemID \n",
    "    data[2] is the Rating\n",
    "    '''\n",
    "    ndcg_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for data in tqdm(dataset, desc='Evaluating'):\n",
    "        # query the model to make predictions if the observed event is a positive interaction (ratings >= 4)\n",
    "        if data[2] >= 4:\n",
    "            y_pred = model.eval_predict_onestep(tf.gather(data, 0))\n",
    "            # print(f\"y_pred:{y_pred}\")\n",
    "            y_true = tf.gather(data, 1)\n",
    "            # print(f\"y_true:{y_true}\")\n",
    "            ndcg = ndcg_at_5(y_true, y_pred)\n",
    "            recall = recall_at_5(y_true, y_pred)\n",
    "            ndcg_scores.append(ndcg)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "    ndcg_result = tf.reduce_mean(ndcg_scores).numpy()\n",
    "    recall_result = tf.reduce_mean(recall_scores).numpy()\n",
    "\n",
    "    return ndcg_result, recall_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = FunkSVDRecommender(m_users=N_TEST_USERS, n_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE, bias_mu=BIAS_MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training from epoch 1\n"
     ]
    }
   ],
   "source": [
    "ckp = tf.train.latest_checkpoint(CKP_DIR)\n",
    "if ckp:\n",
    "    init_epoch = (int(ckp.split('-')[-1]))\n",
    "    ckpt = tf.train.Checkpoint(epoch=tf.Variable(init_epoch), model=model)\n",
    "    ckpt.restore(ckp)\n",
    "    print(f'Resume training from epoch {init_epoch}')\n",
    "else:\n",
    "    init_epoch = 1\n",
    "    ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), model=model)\n",
    "    print(f'Start training from epoch {init_epoch}')\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, CKP_DIR, max_to_keep=3, checkpoint_name='funkSVD_cf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss: 0.9620, val_loss: 0.9300\n",
      "Saved checkpoint for epoch 1: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-1\n",
      "Epoch 2 train_loss: 0.7581, val_loss: 0.8343\n",
      "Saved checkpoint for epoch 2: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-2\n",
      "Epoch 3 train_loss: 0.4916, val_loss: 0.7191\n",
      "Saved checkpoint for epoch 3: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-3\n",
      "Epoch 4 train_loss: 0.2685, val_loss: 0.6043\n",
      "Saved checkpoint for epoch 4: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-4\n",
      "Epoch 5 train_loss: 0.1330, val_loss: 0.5098\n",
      "Saved checkpoint for epoch 5: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-5\n",
      "Epoch 6 train_loss: 0.0611, val_loss: 0.4451\n",
      "Saved checkpoint for epoch 6: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-6\n",
      "Epoch 7 train_loss: 0.0269, val_loss: 0.4079\n",
      "Saved checkpoint for epoch 7: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-7\n",
      "Epoch 8 train_loss: 0.0119, val_loss: 0.3905\n",
      "Saved checkpoint for epoch 8: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-8\n",
      "Epoch 9 train_loss: 0.0054, val_loss: 0.3830\n",
      "Saved checkpoint for epoch 9: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-9\n",
      "Epoch 10 train_loss: 0.0026, val_loss: 0.3794\n",
      "Saved checkpoint for epoch 10: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-10\n",
      "Epoch 11 train_loss: 0.0015, val_loss: 0.3794\n",
      "Saved checkpoint for epoch 11: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-11\n",
      "Epoch 12 train_loss: 0.0013, val_loss: 0.3781\n",
      "Saved checkpoint for epoch 12: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-12\n",
      "Epoch 13 train_loss: 0.0014, val_loss: 0.3784\n",
      "Saved checkpoint for epoch 13: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-13\n",
      "Epoch 14 train_loss: 0.0014, val_loss: 0.3771\n",
      "Saved checkpoint for epoch 14: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-14\n",
      "Epoch 15 train_loss: 0.0014, val_loss: 0.3772\n",
      "Saved checkpoint for epoch 15: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-15\n",
      "Epoch 16 train_loss: 0.0014, val_loss: 0.3766\n",
      "Saved checkpoint for epoch 16: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-16\n",
      "Epoch 17 train_loss: 0.0014, val_loss: 0.3758\n",
      "Saved checkpoint for epoch 17: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-17\n",
      "Epoch 18 train_loss: 0.0014, val_loss: 0.3755\n",
      "Saved checkpoint for epoch 18: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-18\n",
      "Epoch 19 train_loss: 0.0014, val_loss: 0.3748\n",
      "Saved checkpoint for epoch 19: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-19\n",
      "Epoch 20 train_loss: 0.0014, val_loss: 0.3745\n",
      "Saved checkpoint for epoch 20: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-20\n",
      "Epoch 21 train_loss: 0.0014, val_loss: 0.3736\n",
      "Saved checkpoint for epoch 21: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-21\n",
      "Epoch 22 train_loss: 0.0014, val_loss: 0.3730\n",
      "Saved checkpoint for epoch 22: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-22\n",
      "Epoch 23 train_loss: 0.0013, val_loss: 0.3727\n",
      "Saved checkpoint for epoch 23: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-23\n",
      "Epoch 24 train_loss: 0.0013, val_loss: 0.3726\n",
      "Saved checkpoint for epoch 24: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-24\n",
      "Epoch 25 train_loss: 0.0014, val_loss: 0.3718\n",
      "Saved checkpoint for epoch 25: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-25\n",
      "Epoch 26 train_loss: 0.0014, val_loss: 0.3713\n",
      "Saved checkpoint for epoch 26: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-26\n",
      "Epoch 27 train_loss: 0.0014, val_loss: 0.3713\n",
      "Saved checkpoint for epoch 27: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-27\n",
      "Epoch 28 train_loss: 0.0014, val_loss: 0.3704\n",
      "Saved checkpoint for epoch 28: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-28\n",
      "Epoch 29 train_loss: 0.0013, val_loss: 0.3703\n",
      "Saved checkpoint for epoch 29: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-29\n",
      "Epoch 30 train_loss: 0.0013, val_loss: 0.3692\n",
      "Saved checkpoint for epoch 30: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-30\n",
      "Epoch 31 train_loss: 0.0013, val_loss: 0.3696\n",
      "Saved checkpoint for epoch 31: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-31\n",
      "Epoch 32 train_loss: 0.0013, val_loss: 0.3689\n",
      "Saved checkpoint for epoch 32: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-32\n",
      "Epoch 33 train_loss: 0.0013, val_loss: 0.3687\n",
      "Saved checkpoint for epoch 33: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-33\n",
      "Epoch 34 train_loss: 0.0013, val_loss: 0.3683\n",
      "Saved checkpoint for epoch 34: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-34\n",
      "Epoch 35 train_loss: 0.0013, val_loss: 0.3678\n",
      "Saved checkpoint for epoch 35: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-35\n",
      "Epoch 36 train_loss: 0.0013, val_loss: 0.3673\n",
      "Saved checkpoint for epoch 36: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-36\n",
      "Epoch 37 train_loss: 0.0013, val_loss: 0.3667\n",
      "Saved checkpoint for epoch 37: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-37\n",
      "Epoch 38 train_loss: 0.0013, val_loss: 0.3660\n",
      "Saved checkpoint for epoch 38: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-38\n",
      "Epoch 39 train_loss: 0.0013, val_loss: 0.3654\n",
      "Saved checkpoint for epoch 39: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-39\n",
      "Epoch 40 train_loss: 0.0013, val_loss: 0.3653\n",
      "Saved checkpoint for epoch 40: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-40\n",
      "Epoch 41 train_loss: 0.0013, val_loss: 0.3646\n",
      "Saved checkpoint for epoch 41: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-41\n",
      "Epoch 42 train_loss: 0.0013, val_loss: 0.3649\n",
      "Saved checkpoint for epoch 42: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-42\n",
      "Epoch 43 train_loss: 0.0013, val_loss: 0.3641\n",
      "Saved checkpoint for epoch 43: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-43\n",
      "Epoch 44 train_loss: 0.0013, val_loss: 0.3638\n",
      "Saved checkpoint for epoch 44: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-44\n",
      "Epoch 45 train_loss: 0.0013, val_loss: 0.3634\n",
      "Saved checkpoint for epoch 45: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-45\n",
      "Epoch 46 train_loss: 0.0013, val_loss: 0.3630\n",
      "Saved checkpoint for epoch 46: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-46\n",
      "Epoch 47 train_loss: 0.0013, val_loss: 0.3628\n",
      "Saved checkpoint for epoch 47: ./checkpoints/FunkSVD_CF_ver4/funkSVD_cf-47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset_train:\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(data)\n\u001b[0;32m---> 14\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# validating\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset_val:\n",
      "File \u001b[0;32m~/anaconda3/envs/DL-GPU-Eric/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/DL-GPU-Eric/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(init_epoch, INITIAL_N_EPOCHS + 1):\n",
    "    ckpt.epoch.assign_add(1)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # training\n",
    "    for data in dataset_train:\n",
    "        loss = model.train_step(data)\n",
    "        train_loss.append(loss.numpy())\n",
    "\n",
    "    # validating\n",
    "    for data in dataset_val:\n",
    "        loss = model.val_step(data)\n",
    "        val_loss.append(loss.numpy())\n",
    "\n",
    "    # record losses\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # print losses\n",
    "    print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # save checkpoint\n",
    "    save_path = manager.save()\n",
    "    if save_path:\n",
    "        print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training curve\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with the training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_train)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_train)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = tf.data.Dataset.from_tensor_slices(df_val)\n",
    "dataset_eval = dataset_eval.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_eval)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the training environment\n",
    "# train_env = TrainingEnvironment()\n",
    "# train_scores = []\n",
    "\n",
    "\n",
    "# interact_data = []\n",
    "# # Repeat the testing process for 5 times\n",
    "# for i in range(TRAINING_EPISODES):\n",
    "#     print(f'Episode {i+1}:')\n",
    "\n",
    "#     # Start the training process\n",
    "#     # Run as long as there exist some active users\n",
    "#     while train_env.has_next_state():\n",
    "#         # Get the current user id\n",
    "#         cur_user = train_env.get_state()\n",
    "#         # print(f'The current user is user {cur_user}.')\n",
    "\n",
    "#         # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "#         # slate = []\n",
    "#         # for i in range(5):\n",
    "#         #     user_recommendation_sim_based[cur_user].get(i)\n",
    "        \n",
    "#         slate = model.eval_predict_onestep(cur_user)\n",
    "\n",
    "#         # Get the response of the slate from the environment\n",
    "#         clicked_id, in_environment = train_env.get_response(slate)\n",
    "#         # print(f'The click result of recommending {slate} to user {cur_user} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "#         # print(f'User {cur_user} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "\n",
    "#         if clicked_id == -1:\n",
    "#             for item in slate:\n",
    "#                 random_number = random.choice([1, 2, 3])\n",
    "#                 interact_data.append([cur_user, item.numpy(), random_number])\n",
    "#         else:\n",
    "#             interact_data.append([cur_user, clicked_id, 5])\n",
    "\n",
    "#         # [TODO] Update your model here (optional)\n",
    "#         ACCUMULATIVE_DATA_SIZE = 100*BATCH_SIZE\n",
    "#         if len(interact_data) >= ACCUMULATIVE_DATA_SIZE:\n",
    "#             print(f'Updating Model')\n",
    "#             df_interact = pd.DataFrame(interact_data[:ACCUMULATIVE_DATA_SIZE], columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "#             df_interact.to_csv('./interact_data/interact_data_based_on_sim.csv', mode='a', header=False, index=False)\n",
    "#             interact_data = interact_data[ACCUMULATIVE_DATA_SIZE:]\n",
    "\n",
    "#             df_interact = pd.concat([df_train, df_interact], axis=0)\n",
    "#             df_interact_norm = df_interact.copy(deep=True)\n",
    "#             df_interact_norm['rating'] -= 3\n",
    "#             df_interact_norm['rating'] /= 2\n",
    "\n",
    "#             dataset_interact = tf.data.Dataset.from_tensor_slices(df_interact_norm)\n",
    "#             dataset_interact = dataset_interact.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "#                                                 .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "            \n",
    "\n",
    "#             # train the model\n",
    "#             train_losses = []\n",
    "#             val_losses = []\n",
    "\n",
    "#             for epoch in range(1, N_EPOCHS + 1):\n",
    "#                 train_loss = []\n",
    "#                 val_loss = []\n",
    "#                 # print(f'Epoch {epoch}:')\n",
    "\n",
    "#                 # training\n",
    "#                 for data in dataset_interact:\n",
    "#                     loss = model.train_step(data)\n",
    "#                     train_loss.append(loss.numpy())\n",
    "\n",
    "#                 # validating\n",
    "#                 for data in dataset_val:\n",
    "#                     loss = model.val_step(data)\n",
    "#                     val_loss.append(loss.numpy())\n",
    "\n",
    "#                 # record losses\n",
    "#                 avg_train_loss = np.mean(train_loss)\n",
    "#                 avg_val_loss = np.mean(val_loss)\n",
    "#                 train_losses.append(avg_train_loss)\n",
    "#                 val_losses.append(avg_val_loss)\n",
    "\n",
    "#                 # print losses\n",
    "#                 print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}\\r', end=\"\")\n",
    "\n",
    "#             print(f'')\n",
    "\n",
    "\n",
    "#     # Record the score of this testing episode\n",
    "#     train_scores.append(train_env.get_score())\n",
    "\n",
    "#     # Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "#     train_env.reset()\n",
    "#     print(f'Have collected {len(interact_data)} interact data\\n')\n",
    "\n",
    "#     # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "#     # [TODO] Code for deleting your model weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the average scores \n",
    "# avg_scores = [np.average(train_scores) for train_scores in zip(*train_scores)]\n",
    "# df_train_score = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "# df_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'training score: {1-(df_train_score[\"avg_score\"].sum()/2000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training curve\n",
    "# plt.plot(train_losses, label='train_loss')\n",
    "# plt.plot(val_losses, label='val_loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Loss curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with the training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = tf.data.Dataset.from_tensor_slices(df_interact)\n",
    "# variable = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# ndcg_result, recall_result = evaluate(model, dataset_train)\n",
    "# print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val = tf.data.Dataset.from_tensor_slices(df_val)\n",
    "# dataset_val = dataset_val.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# ndcg_result, recall_result = evaluate(model, dataset_val)\n",
    "# print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save FunkSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# model.save_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp = tf.train.latest_checkpoint(CKP_DIR)\n",
    "if ckp:\n",
    "    init_epoch = (int(ckp.split('-')[-1]))\n",
    "    ckpt = tf.train.Checkpoint(epoch=tf.Variable(init_epoch), model=model)\n",
    "    ckpt.restore(ckp)\n",
    "    print(f'Restore checkpoint from latest epoch {init_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.empty((N_TEST_USERS, 2000))\n",
    "\n",
    "for user_id in tqdm(range(N_TEST_USERS)):\n",
    "    sorted_y_pred, sorted_indices = model.eval_predict_onestep_env(user_id)\n",
    "    # print(\"sorted_indices:\\n\", sorted_indices)\n",
    "    # print(\"sorted_y_pred:\\n\", sorted_y_pred)\n",
    "    \n",
    "    sorted_y_pred_np = sorted_y_pred.numpy()\n",
    "    total_weights = sum(sorted_y_pred_np)\n",
    "    normalized_weights = (sorted_y_pred_np / total_weights).tolist()\n",
    "    normalized_weights[-1] = 1.0 - sum(normalized_weights[:-1])\n",
    "    prob[user_id] = normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(1):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "    \n",
    "    # funk_SVD = FunkSVDRecommender(m_users=N_TEST_USERS, n_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE, bias_mu=BIAS_MU)\n",
    "    # funk_SVD.load_model(MODEL_PATH)\n",
    "\n",
    "    ckp = tf.train.latest_checkpoint(CKP_DIR)\n",
    "    if ckp:\n",
    "        init_epoch = (int(ckp.split('-')[-1]))\n",
    "        ckpt = tf.train.Checkpoint(epoch=tf.Variable(init_epoch), model=model)\n",
    "        ckpt.restore(ckp)\n",
    "        print(f'Restore checkpoint from latest epoch {init_epoch}')\n",
    "\n",
    "    choosen_item = np.zeros((N_TEST_USERS, N_ITEMS), dtype=np.int8)\n",
    "    \n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            # slate = random.sample(item_ids, k=SLATE_SIZE)\n",
    "            \n",
    "            \n",
    "            sorted_y_pred, sorted_indices = model.eval_predict_onestep_env(cur_user)\n",
    "            sorted_y_pred_np = sorted_y_pred.numpy()\n",
    "            total_weights = sum(sorted_y_pred_np)\n",
    "            normalized_weights = (sorted_y_pred_np / total_weights).tolist()\n",
    "            normalized_weights[-1] = 1.0 - sum(normalized_weights[:-1])\n",
    "            \n",
    "            # slate嚴格挑選，選過就不選\n",
    "            # slate = []\n",
    "            # for item_id in sorted_indices:\n",
    "                # if choosen_item[cur_user][item_id] == 0:\n",
    "                    # slate.append(item_id)\n",
    "                # if len(slate) == 5:\n",
    "                    # break\n",
    "            \n",
    "            # # 以y_pred為權重，隨機挑選5個當作slate\n",
    "            slate = np.random.choice(sorted_indices, size=5, replace=False, p=normalized_weights)\n",
    "            \n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "            # if (clicked_id != -1):\n",
    "            #     choosen_item[cur_user][clicked_id] = 1\n",
    "\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "\n",
    "\n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'testing score: {1-(df_result[\"avg_score\"].sum()/2000)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-GPU-Eric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
