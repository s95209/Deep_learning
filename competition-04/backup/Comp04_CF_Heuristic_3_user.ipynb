{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DataLab Cup 4: Recommender Systems</center>\n",
    "<center>Shan-Hung Wu & DataLab</center>\n",
    "<center>Fall 2023</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: 陳瑜旋轉陳玟旋轉陳瑜旋\n",
    "\n",
    "Team Member: 111501538 劉杰閎、111062588 陳玟璇、111062697 吳律穎"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform: [Kaggle](https://www.kaggle.com/t/b06e248a3827434f80c4fdc6009d5fe0)\n",
    "\n",
    "Please download the dataset and the environment source code from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 22:56:19.202720: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 22:56:20.853764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.853929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.859759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.859936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.860074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.860233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.861146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 22:56:20.861954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.862176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:20.862308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:21.370576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:21.370771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:21.370889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 22:56:21.370978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci "
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[42558, 65272, 13353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[146057, 195688, 143652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[67551, 85247, 33714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[116097, 192703, 103229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[68756, 140123, 135289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[95090, 131393, 130239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[2360, 147130, 8145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[99794, 138694, 157888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[55561, 60372, 51442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[125409, 77906, 124792]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   history\n",
       "0           0     [42558, 65272, 13353]\n",
       "1           1  [146057, 195688, 143652]\n",
       "2           2     [67551, 85247, 33714]\n",
       "3           3  [116097, 192703, 103229]\n",
       "4           4   [68756, 140123, 135289]\n",
       "...       ...                       ...\n",
       "1995     1995   [95090, 131393, 130239]\n",
       "1996     1996      [2360, 147130, 8145]\n",
       "1997     1997   [99794, 138694, 157888]\n",
       "1998     1998     [55561, 60372, 51442]\n",
       "1999     1999   [125409, 77906, 124792]\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "df_user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \n",
       "0       Health experts said it is too early to predict...  \n",
       "1       He was subdued by passengers and crew when he ...  \n",
       "2       \"Until you have a dog you don't understand wha...  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  \n",
       "...                                                   ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...  \n",
       "209525  CORRECTION: An earlier version of this story i...  \n",
       "209526  The five-time all-star center tore into his te...  \n",
       "\n",
       "[209527 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "df_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embedding from item descriptions\n",
    "\n",
    "在這裡我們針對每一個item的描述，使用`SentenceTransformer`去做Text Embedding，可以得到每一個item都有headline的embedding跟short_description的embedding，兩者的維度都是768。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline_embeddings</th>\n",
       "      <th>short_description_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>[-0.054995973, 0.10514701, 0.0009537986, -0.07...</td>\n",
       "      <td>[0.04689467, 0.089309394, -0.018575395, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>[-0.020863444, 0.011131575, 0.0013632453, -0.0...</td>\n",
       "      <td>[0.017128233, -0.0062120855, 0.015252358, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>[0.017761054, 0.053476874, 6.918786e-05, -0.03...</td>\n",
       "      <td>[0.10238154, 0.07736524, 0.0020822838, -0.0614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>[-0.0029250348, 0.01137404, 0.0045979875, -0.0...</td>\n",
       "      <td>[0.04334459, 0.056244634, 0.0071496996, -0.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>[-0.0049342206, 0.053551663, 0.027952224, -0.0...</td>\n",
       "      <td>[-0.0066743735, 0.03416268, -0.00058029604, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "      <td>[0.041218493, -0.007820907, -0.01887703, -0.02...</td>\n",
       "      <td>[-0.029524302, -0.0045847334, -0.054970894, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td>[-0.047861934, -0.027825285, -0.0048302715, -0...</td>\n",
       "      <td>[0.03547541, -0.027677324, 0.019167567, -0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td>[-0.0816778, 0.022369152, 0.027179016, 0.02018...</td>\n",
       "      <td>[-0.020275101, 0.10664522, -0.007810726, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td>[-0.04274766, 0.12479968, -0.047635496, -0.057...</td>\n",
       "      <td>[0.044633802, 0.014033731, -0.004920267, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td>[-0.026855215, -0.03475871, -0.0026978385, -0....</td>\n",
       "      <td>[-0.0026186472, -0.025399072, 0.01087954, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \\\n",
       "0       Health experts said it is too early to predict...   \n",
       "1       He was subdued by passengers and crew when he ...   \n",
       "2       \"Until you have a dog you don't understand wha...   \n",
       "3       \"Accidentally put grown-up toothpaste on my to...   \n",
       "4       Amy Cooper accused investment firm Franklin Te...   \n",
       "...                                                   ...   \n",
       "209522  Verizon Wireless and AT&T are already promotin...   \n",
       "209523  Afterward, Azarenka, more effusive with the pr...   \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...   \n",
       "209525  CORRECTION: An earlier version of this story i...   \n",
       "209526  The five-time all-star center tore into his te...   \n",
       "\n",
       "                                      headline_embeddings  \\\n",
       "0       [-0.054995973, 0.10514701, 0.0009537986, -0.07...   \n",
       "1       [-0.020863444, 0.011131575, 0.0013632453, -0.0...   \n",
       "2       [0.017761054, 0.053476874, 6.918786e-05, -0.03...   \n",
       "3       [-0.0029250348, 0.01137404, 0.0045979875, -0.0...   \n",
       "4       [-0.0049342206, 0.053551663, 0.027952224, -0.0...   \n",
       "...                                                   ...   \n",
       "209522  [0.041218493, -0.007820907, -0.01887703, -0.02...   \n",
       "209523  [-0.047861934, -0.027825285, -0.0048302715, -0...   \n",
       "209524  [-0.0816778, 0.022369152, 0.027179016, 0.02018...   \n",
       "209525  [-0.04274766, 0.12479968, -0.047635496, -0.057...   \n",
       "209526  [-0.026855215, -0.03475871, -0.0026978385, -0....   \n",
       "\n",
       "                             short_description_embeddings  \n",
       "0       [0.04689467, 0.089309394, -0.018575395, -0.029...  \n",
       "1       [0.017128233, -0.0062120855, 0.015252358, 0.02...  \n",
       "2       [0.10238154, 0.07736524, 0.0020822838, -0.0614...  \n",
       "3       [0.04334459, 0.056244634, 0.0071496996, -0.057...  \n",
       "4       [-0.0066743735, 0.03416268, -0.00058029604, 0....  \n",
       "...                                                   ...  \n",
       "209522  [-0.029524302, -0.0045847334, -0.054970894, -0...  \n",
       "209523  [0.03547541, -0.027677324, 0.019167567, -0.007...  \n",
       "209524  [-0.020275101, 0.10664522, -0.007810726, -0.01...  \n",
       "209525  [0.044633802, 0.014033731, -0.004920267, -0.02...  \n",
       "209526  [-0.0026186472, -0.025399072, 0.01087954, -0.0...  \n",
       "\n",
       "[209527 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = './dataset/'\n",
    "if os.path.exists(dataset_dir + 'train_data_embedding.pkl'):\n",
    "    df_item_train = pd.read_pickle(dataset_dir + 'train_data_embedding.pkl')\n",
    "else:\n",
    "    sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "    df_item_train = pd.read_json(ITEM_DATA, lines=True)\n",
    "    df_item_train['headline_embeddings'] = df_item_train['headline'].apply(lambda x: sbert.encode(x))\n",
    "    df_item_train['short_description_embeddings'] = df_item_train['short_description'].apply(lambda x: sbert.encode(x))\n",
    "    df_item_train.to_pickle(dataset_dir + 'train_data_embedding.pkl')\n",
    "\n",
    "df_item_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating User Embedding dataframe\n",
    "\n",
    "+ 我們會建立一個 User Embedding dataframe來代表每一個User的feature\n",
    "+ 計算的方式就是透過每一個user之前點過哪三個item，我們去拿那三個item的embedding出來取平均，就當作這個user的embedding，最後一個column是把headline跟short description concat起來。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "EMBEDDING_DIM = 768\n",
    "HISTORY_SIZE = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(dataset_dir + 'user_embedding.pkl'):\n",
    "    df_user_embedding = pd.read_pickle(dataset_dir+'user_embedding.pkl')\n",
    "else:\n",
    "    df_user_embedding_list = []\n",
    "    for user in range(N_USERS):\n",
    "        # print(df_user.iloc[user])\n",
    "        sum_headline = tf.zeros(shape=(EMBEDDING_DIM,)) # since all embeddings are (768,)\n",
    "        sum_short_description = tf.zeros(shape=(EMBEDDING_DIM,)) # since all embeddings are (768,)\n",
    "        for item in df_user.iloc[user][\"history\"]:\n",
    "            headline_tensor = tf.convert_to_tensor(df_item_train.iloc[item][\"headline_embeddings\"])\n",
    "            short_description_tensor = tf.convert_to_tensor(df_item_train.iloc[item][\"short_description_embeddings\"])\n",
    "            sum_headline += headline_tensor\n",
    "            sum_short_description += short_description_tensor\n",
    "        sum_headline = tf.divide(sum_headline, HISTORY_SIZE)\n",
    "        sum_short_description = tf.divide(sum_short_description, HISTORY_SIZE)\n",
    "        concat_embedding = tf.concat([sum_headline, sum_short_description],axis=0)\n",
    "        df_user_embedding_list.append([user, sum_headline.numpy(), sum_short_description.numpy(), concat_embedding.numpy()])\n",
    "    df_user_embedding = pd.DataFrame(df_user_embedding_list, columns = ['user_id', 'headline_embedding', 'short_description_embedding','concat_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                                                                        0\n",
      "headline_embedding             [0.038156908, 0.041387293, -0.004624029, -0.02...\n",
      "short_description_embedding    [0.03716896, 0.0512002, -0.025162613, -0.01830...\n",
      "concat_embeddings              [0.038156908, 0.041387293, -0.004624029, -0.02...\n",
      "Name: 0, dtype: object\n",
      "0.03716896\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>headline_embedding</th>\n",
       "      <th>short_description_embedding</th>\n",
       "      <th>concat_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.038156908, 0.041387293, -0.004624029, -0.02...</td>\n",
       "      <td>[0.03716896, 0.0512002, -0.025162613, -0.01830...</td>\n",
       "      <td>[0.038156908, 0.041387293, -0.004624029, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.01718974, 0.04380578, -0.0033005949, 0.026...</td>\n",
       "      <td>[-0.022690356, 0.041603807, -0.009130617, -0.0...</td>\n",
       "      <td>[-0.01718974, 0.04380578, -0.0033005949, 0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0044823308, -0.017107317, -0.038572405, -0...</td>\n",
       "      <td>[0.03541447, 0.021701857, -0.016264068, -0.025...</td>\n",
       "      <td>[-0.0044823308, -0.017107317, -0.038572405, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.03414116, 0.035626348, -0.024177575, 0.043...</td>\n",
       "      <td>[-0.032475274, 0.034354758, -0.0064822477, 0.0...</td>\n",
       "      <td>[-0.03414116, 0.035626348, -0.024177575, 0.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.0039870082, 0.082041055, -0.01948834, -0.0...</td>\n",
       "      <td>[0.009200389, 0.0539891, -0.026606128, -0.0117...</td>\n",
       "      <td>[-0.0039870082, 0.082041055, -0.01948834, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 headline_embedding  \\\n",
       "0        0  [0.038156908, 0.041387293, -0.004624029, -0.02...   \n",
       "1        1  [-0.01718974, 0.04380578, -0.0033005949, 0.026...   \n",
       "2        2  [-0.0044823308, -0.017107317, -0.038572405, -0...   \n",
       "3        3  [-0.03414116, 0.035626348, -0.024177575, 0.043...   \n",
       "4        4  [-0.0039870082, 0.082041055, -0.01948834, -0.0...   \n",
       "\n",
       "                         short_description_embedding  \\\n",
       "0  [0.03716896, 0.0512002, -0.025162613, -0.01830...   \n",
       "1  [-0.022690356, 0.041603807, -0.009130617, -0.0...   \n",
       "2  [0.03541447, 0.021701857, -0.016264068, -0.025...   \n",
       "3  [-0.032475274, 0.034354758, -0.0064822477, 0.0...   \n",
       "4  [0.009200389, 0.0539891, -0.026606128, -0.0117...   \n",
       "\n",
       "                                   concat_embeddings  \n",
       "0  [0.038156908, 0.041387293, -0.004624029, -0.02...  \n",
       "1  [-0.01718974, 0.04380578, -0.0033005949, 0.026...  \n",
       "2  [-0.0044823308, -0.017107317, -0.038572405, -0...  \n",
       "3  [-0.03414116, 0.035626348, -0.024177575, 0.043...  \n",
       "4  [-0.0039870082, 0.082041055, -0.01948834, -0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_user_embedding.iloc[0])\n",
    "print(df_user_embedding.iloc[0][\"concat_embeddings\"][768])\n",
    "display(df_user_embedding.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Item embedding dataframe\n",
    "\n",
    "那我們也重新去建立一個item embedding，丟棄調原本對item的description，最後一個column是把headline跟short description concat起來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(dataset_dir+'item_embedding.pkl')):\n",
    "    df_item_embedding = pd.read_pickle(dataset_dir+'item_embedding.pkl')\n",
    "else:\n",
    "    item_embedding_list = []\n",
    "    for item in range(len(df_item_train)):\n",
    "        headline_tensor = tf.convert_to_tensor(df_item_train.iloc[item][\"headline_embeddings\"])\n",
    "        short_description_tensor = tf.convert_to_tensor(df_item_train.iloc[item][\"short_description_embeddings\"])\n",
    "        concat_embedding = tf.concat([headline_tensor, short_description_tensor],axis=0)\n",
    "        item_embedding_list.append([item, headline_tensor.numpy(), short_description_tensor.numpy(), concat_embedding.numpy()])\n",
    "    df_item_embedding = pd.DataFrame(item_embedding_list, columns=[\"item_id\",\"headline_embeddings\",\"short_description_embeddings\",\"concat_embeddings\"])\n",
    "    df_item_embedding.to_pickle(dataset_dir + 'item_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id                                                                         0\n",
      "headline_embeddings             [-0.054995973, 0.10514701, 0.0009537986, -0.07...\n",
      "short_description_embeddings    [0.04689467, 0.089309394, -0.018575395, -0.029...\n",
      "concat_embeddings               [-0.054995973, 0.10514701, 0.0009537986, -0.07...\n",
      "Name: 0, dtype: object\n",
      "0.04689467\n",
      "len of item dataframe is  209527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline_embeddings</th>\n",
       "      <th>short_description_embeddings</th>\n",
       "      <th>concat_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.054995973, 0.10514701, 0.0009537986, -0.07...</td>\n",
       "      <td>[0.04689467, 0.089309394, -0.018575395, -0.029...</td>\n",
       "      <td>[-0.054995973, 0.10514701, 0.0009537986, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.020863444, 0.011131575, 0.0013632453, -0.0...</td>\n",
       "      <td>[0.017128233, -0.0062120855, 0.015252358, 0.02...</td>\n",
       "      <td>[-0.020863444, 0.011131575, 0.0013632453, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.017761054, 0.053476874, 6.918786e-05, -0.03...</td>\n",
       "      <td>[0.10238154, 0.07736524, 0.0020822838, -0.0614...</td>\n",
       "      <td>[0.017761054, 0.053476874, 6.918786e-05, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.0029250348, 0.01137404, 0.0045979875, -0.0...</td>\n",
       "      <td>[0.04334459, 0.056244634, 0.0071496996, -0.057...</td>\n",
       "      <td>[-0.0029250348, 0.01137404, 0.0045979875, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.0049342206, 0.053551663, 0.027952224, -0.0...</td>\n",
       "      <td>[-0.0066743735, 0.03416268, -0.00058029604, 0....</td>\n",
       "      <td>[-0.0049342206, 0.053551663, 0.027952224, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                headline_embeddings  \\\n",
       "0        0  [-0.054995973, 0.10514701, 0.0009537986, -0.07...   \n",
       "1        1  [-0.020863444, 0.011131575, 0.0013632453, -0.0...   \n",
       "2        2  [0.017761054, 0.053476874, 6.918786e-05, -0.03...   \n",
       "3        3  [-0.0029250348, 0.01137404, 0.0045979875, -0.0...   \n",
       "4        4  [-0.0049342206, 0.053551663, 0.027952224, -0.0...   \n",
       "\n",
       "                        short_description_embeddings  \\\n",
       "0  [0.04689467, 0.089309394, -0.018575395, -0.029...   \n",
       "1  [0.017128233, -0.0062120855, 0.015252358, 0.02...   \n",
       "2  [0.10238154, 0.07736524, 0.0020822838, -0.0614...   \n",
       "3  [0.04334459, 0.056244634, 0.0071496996, -0.057...   \n",
       "4  [-0.0066743735, 0.03416268, -0.00058029604, 0....   \n",
       "\n",
       "                                   concat_embeddings  \n",
       "0  [-0.054995973, 0.10514701, 0.0009537986, -0.07...  \n",
       "1  [-0.020863444, 0.011131575, 0.0013632453, -0.0...  \n",
       "2  [0.017761054, 0.053476874, 6.918786e-05, -0.03...  \n",
       "3  [-0.0029250348, 0.01137404, 0.0045979875, -0.0...  \n",
       "4  [-0.0049342206, 0.053551663, 0.027952224, -0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_item_embedding.iloc[0])\n",
    "print(df_item_embedding.iloc[0][\"concat_embeddings\"][768])\n",
    "print(\"len of item dataframe is \", len(df_item_embedding))\n",
    "display(df_item_embedding.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item Similarity Matrix\n",
    "\n",
    "在這個地方，我們是透過計算每一個user跟每一個item之間的餘弦相似度，並存成一個dataframe\n",
    "\n",
    "舉例來說，row=10, item=100，這個對應到的值就是user 10跟item 100的相似度，越高代表這個user有越高的機率會喜歡這個item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset/'\n",
    "if os.path.exists(dataset_dir + 'user_item_similarity.pkl'):\n",
    "    df_user_item_similarity = pd.read_pickle(dataset_dir + 'user_item_similarity.pkl')\n",
    "else:\n",
    "    with open(dataset_dir+'user_item_similarity.txt','a') as fin:\n",
    "        user_item_similarity_matrix = []\n",
    "        for user in range(N_USERS):\n",
    "            cosine_similarity_list = []\n",
    "            for item in range(N_ITEMS):\n",
    "                # calculating cosine similarity\n",
    "                cosine_similarity = (1-spatial.distance.cosine(df_user_embedding.iloc[user][\"concat_embeddings\"], df_item_embedding.iloc[item][\"concat_embeddings\"]))\n",
    "                cosine_similarity_list.append(cosine_similarity)    \n",
    "            \n",
    "            user_item_similarity_matrix.append(cosine_similarity_list)\n",
    "            fin.write(\",\".join([str(x) for x in cosine_similarity_list]))\n",
    "            fin.write('\\n')\n",
    "            fin.flush()\n",
    "        df_user_item_similarity = pd.DataFrame(user_item_similarity_matrix)\n",
    "        df_user_item_similarity.to_pickle(dataset_dir + 'user_item_similarity.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221764</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1  0.221764  0.055316  0.112049  0.190925  0.091024  0.078525  0.017141   \n",
       "2  0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3  0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4  0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "\n",
       "     7         8         9       ...    209517    209518    209519    209520  \\\n",
       "0  0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302  0.062932   \n",
       "1  0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543 -0.005578   \n",
       "2  0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249  0.043811   \n",
       "3  0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552  0.072513   \n",
       "4  0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474  0.110714   \n",
       "\n",
       "     209521    209522    209523    209524    209525    209526  \n",
       "0  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "\n",
       "[5 rows x 209527 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 209527)\n"
     ]
    }
   ],
   "source": [
    "display(df_user_item_similarity.head(5))\n",
    "print(df_user_item_similarity.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Environments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Interact with training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          40075\n",
      "1          96295\n",
      "2         187611\n",
      "3         139955\n",
      "4         191058\n",
      "           ...  \n",
      "209522      9102\n",
      "209523      9810\n",
      "209524     65272\n",
      "209525     42558\n",
      "209526     13353\n",
      "Name: 0, Length: 209527, dtype: int64\n",
      "max similarity index:  13353\n",
      "min similarity index:  40075\n",
      "max similarity score:  0.6880343556404114\n",
      "min similarity score:  -0.12662772834300995\n",
      "difference between max score and min score: 0.8146620839834213\n",
      "difference between max score and min score: 0.04912831587716937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221764</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1     0.221764  0.055316  0.112049  0.190925  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy from origin df.\n",
    "df_similarity = df_user_item_similarity.copy()\n",
    "sorted_indices = np.argsort(df_similarity.iloc[0])\n",
    "print((sorted_indices))\n",
    "sorted_indices = list(sorted_indices)\n",
    "print('max similarity index: ', sorted_indices[-1])\n",
    "print('min similarity index: ', sorted_indices[0])\n",
    "print('max similarity score: ', df_similarity.iloc[0][sorted_indices[-1]])\n",
    "print('min similarity score: ', df_similarity.iloc[0][sorted_indices[0]])\n",
    "print('difference between max score and min score:', df_similarity.iloc[0][sorted_indices[-1]] - df_similarity.iloc[0][sorted_indices[0]])\n",
    "print('difference between max score and min score:', df_similarity.iloc[1][sorted_indices[-1]] - df_similarity.iloc[1][sorted_indices[0]])\n",
    "\n",
    "df_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡可以去把最新的epoch的matrix給讀出來繼續拿來訓練或是拿來測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/\n",
      "Load weights with epoch119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1    -1.000000  0.055316  0.112049  0.171833  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload last training dataframe.\n",
    "print(dataset_dir)\n",
    "if(os.path.exists(dataset_dir+'test/epoch_119.pkl')):\n",
    "    df_next = pd.read_pickle(dataset_dir+'test/epoch_119.pkl')\n",
    "    print(\"Load weights with epoch119\")\n",
    "    display(df_next)\n",
    "else:\n",
    "    print('path is not exist')\n",
    "    df_next = df_user_item_similarity.copy()\n",
    "    display(df_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-15 22:56:36] We assume remove HIGH_SIMILARITY_RATE_THRESHOLD would lead to better result\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def time_log(str):\n",
    "  logStr = f'[{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}] {str}'\n",
    "  logStr = logStr.replace('\\n', '')\n",
    "  print(logStr)\n",
    "  fout = open('./dataset/test/test_training.log', 'a')\n",
    "  fout.write(f'{logStr}\\n')\n",
    "  fout.close()\n",
    "\n",
    "time_log(\"We assume remove HIGH_SIMILARITY_RATE_THRESHOLD would lead to better result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_SIMILARITY_RATE_THRESHOLD = 0.0\n",
    "training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在訓練的時候我主要用了兩個dataframe來做紀錄，第一個是`df_next`，另一個是`df_current`，在每一次的iteration開始前，`df_current`會從`df_next` copy一份，並在每一次要推薦使用者的時候，會根據 `df_current[user_id]`中相似度最高的前五個item優先進行推薦，推薦完以後這次的iteration就不該再推薦他，因此我會把下次的iteration設為1，而這次設為-1；那如果我挑了五個推薦，結果這個user一個都沒點，我就會給這些item一些penalty，所以把這些item的分數都乘上0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not train this time\n"
     ]
    }
   ],
   "source": [
    "if(training):\n",
    "    # Initialize the training environment\n",
    "    train_env = TrainingEnvironment()\n",
    "\n",
    "    training_scores = []\n",
    "    # Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "    train_env.reset()\n",
    "    for epoch in range(1,100):\n",
    "        # APPLY CHANGE TO CURRENT DF.\n",
    "        df_current = df_next.copy()\n",
    "        with tqdm(desc='Training') as pbar:\n",
    "            # Check if there exist any active users in the environment\n",
    "            while (train_env.has_next_state()):\n",
    "\n",
    "                # print(f'There is {\"still some\" if train_env.has_next_state() else \"no\"} active users in the training environment.')\n",
    "\n",
    "                # Get the current user ID\n",
    "                user_id = train_env.get_state()\n",
    "                sorted_indices = np.argsort(df_current.iloc[user_id])\n",
    "                # Get top5 similarity response of recommending the slate to the current user\n",
    "                slate = list(sorted_indices[-5:])\n",
    "                clicked_id, in_environment = train_env.get_response(slate)\n",
    "                # Update similarity matrix here\n",
    "                if(clicked_id == -1): # mean there is no click in this item\n",
    "                    for item in slate:\n",
    "                        # if(df_current.iloc[user_id][item] >= HIGH_SIMILARITY_RATE_THRESHOLD): # used to click, but not click this time\n",
    "                        df_current.iloc[user_id][item] *= 0.9\n",
    "                        df_next.iloc[user_id][item] *= 0.9\n",
    "                        # else:\n",
    "                        #     df_current.iloc[user_id][item] = -1\n",
    "                        #     df_next.iloc[user_id][item] = -1\n",
    "\n",
    "                else:\n",
    "                    for item in slate:\n",
    "                        if(item == clicked_id):\n",
    "                            df_current.iloc[user_id][item] = -1\n",
    "                            df_next.iloc[user_id][item] = 1\n",
    "                        # else:\n",
    "                        #     df_current.iloc[user_id][item] = 0.8                \n",
    "                        #     df_next.iloc[user_id][item] = 0.8\n",
    "                # print(f'The click result of recommending {slate} to user {user_id} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "                # print(f'User {user_id} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "                pbar.update(1)\n",
    "        training_scores.append(train_env.get_score())\n",
    "        # print(f\"Epoch: {25+epoch}, Score: {sum(train_env.get_score())}\")\n",
    "        time_log(f\"Epoch: {epoch+92}, Score: {sum(train_env.get_score())}, Iteration:{pbar}\")\n",
    "        df_next.to_pickle(f\"./dataset/test/epoch_{epoch+92}.pkl\")\n",
    "        train_env.reset()\n",
    "\n",
    "    # Get the normalized session length score of all users\n",
    "    avg_train_scores = [np.average(score) for score in zip(*training_scores)]\n",
    "    df_train_score = pd.DataFrame([[user_id, score] for user_id, score in enumerate(avg_train_scores)], columns=['user_id', 'avg_score'])\n",
    "    display(df_train_score)\n",
    "    print(training_scores)\n",
    "    total_score = df_train_score['avg_score'].sum()\n",
    "    print(f\"Total train score:{total_score}\")\n",
    "else:\n",
    "    print(\"Not train this time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider user-user similarity (Create user-user similarity matrix)\n",
    "\n",
    "在這裡，為了考慮user與user之間的相似度，我將user embedding又取出來了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>headline_embedding</th>\n",
       "      <th>short_description_embedding</th>\n",
       "      <th>concat_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.038156908, 0.041387293, -0.004624029, -0.02...</td>\n",
       "      <td>[0.03716896, 0.0512002, -0.025162613, -0.01830...</td>\n",
       "      <td>[0.038156908, 0.041387293, -0.004624029, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.01718974, 0.04380578, -0.0033005949, 0.026...</td>\n",
       "      <td>[-0.022690356, 0.041603807, -0.009130617, -0.0...</td>\n",
       "      <td>[-0.01718974, 0.04380578, -0.0033005949, 0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0044823308, -0.017107317, -0.038572405, -0...</td>\n",
       "      <td>[0.03541447, 0.021701857, -0.016264068, -0.025...</td>\n",
       "      <td>[-0.0044823308, -0.017107317, -0.038572405, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.03414116, 0.035626348, -0.024177575, 0.043...</td>\n",
       "      <td>[-0.032475274, 0.034354758, -0.0064822477, 0.0...</td>\n",
       "      <td>[-0.03414116, 0.035626348, -0.024177575, 0.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.0039870082, 0.082041055, -0.01948834, -0.0...</td>\n",
       "      <td>[0.009200389, 0.0539891, -0.026606128, -0.0117...</td>\n",
       "      <td>[-0.0039870082, 0.082041055, -0.01948834, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[0.007958271, 0.06905828, -0.012985666, 0.0113...</td>\n",
       "      <td>[-0.005231034, 0.03755425, -0.013397035, -0.01...</td>\n",
       "      <td>[0.007958271, 0.06905828, -0.012985666, 0.0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[-0.036823038, 0.03161138, -0.017325308, 0.003...</td>\n",
       "      <td>[-0.010244309, -0.01270321, 0.00085817085, -0....</td>\n",
       "      <td>[-0.036823038, 0.03161138, -0.017325308, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[0.02073842, 0.056454603, 0.000992029, 0.00940...</td>\n",
       "      <td>[0.012727796, 0.0049337894, -0.012769024, 0.02...</td>\n",
       "      <td>[0.02073842, 0.056454603, 0.000992029, 0.00940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[0.016565206, 0.06024626, -0.0010410805, -0.01...</td>\n",
       "      <td>[0.025898555, 0.046939295, -0.02147156, -0.017...</td>\n",
       "      <td>[0.016565206, 0.06024626, -0.0010410805, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[0.005492252, 0.064615436, -0.0025653813, 0.01...</td>\n",
       "      <td>[0.0068310047, 0.07291591, -0.0014106488, 0.00...</td>\n",
       "      <td>[0.005492252, 0.064615436, -0.0025653813, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                 headline_embedding  \\\n",
       "0           0  [0.038156908, 0.041387293, -0.004624029, -0.02...   \n",
       "1           1  [-0.01718974, 0.04380578, -0.0033005949, 0.026...   \n",
       "2           2  [-0.0044823308, -0.017107317, -0.038572405, -0...   \n",
       "3           3  [-0.03414116, 0.035626348, -0.024177575, 0.043...   \n",
       "4           4  [-0.0039870082, 0.082041055, -0.01948834, -0.0...   \n",
       "...       ...                                                ...   \n",
       "1995     1995  [0.007958271, 0.06905828, -0.012985666, 0.0113...   \n",
       "1996     1996  [-0.036823038, 0.03161138, -0.017325308, 0.003...   \n",
       "1997     1997  [0.02073842, 0.056454603, 0.000992029, 0.00940...   \n",
       "1998     1998  [0.016565206, 0.06024626, -0.0010410805, -0.01...   \n",
       "1999     1999  [0.005492252, 0.064615436, -0.0025653813, 0.01...   \n",
       "\n",
       "                            short_description_embedding  \\\n",
       "0     [0.03716896, 0.0512002, -0.025162613, -0.01830...   \n",
       "1     [-0.022690356, 0.041603807, -0.009130617, -0.0...   \n",
       "2     [0.03541447, 0.021701857, -0.016264068, -0.025...   \n",
       "3     [-0.032475274, 0.034354758, -0.0064822477, 0.0...   \n",
       "4     [0.009200389, 0.0539891, -0.026606128, -0.0117...   \n",
       "...                                                 ...   \n",
       "1995  [-0.005231034, 0.03755425, -0.013397035, -0.01...   \n",
       "1996  [-0.010244309, -0.01270321, 0.00085817085, -0....   \n",
       "1997  [0.012727796, 0.0049337894, -0.012769024, 0.02...   \n",
       "1998  [0.025898555, 0.046939295, -0.02147156, -0.017...   \n",
       "1999  [0.0068310047, 0.07291591, -0.0014106488, 0.00...   \n",
       "\n",
       "                                      concat_embeddings  \n",
       "0     [0.038156908, 0.041387293, -0.004624029, -0.02...  \n",
       "1     [-0.01718974, 0.04380578, -0.0033005949, 0.026...  \n",
       "2     [-0.0044823308, -0.017107317, -0.038572405, -0...  \n",
       "3     [-0.03414116, 0.035626348, -0.024177575, 0.043...  \n",
       "4     [-0.0039870082, 0.082041055, -0.01948834, -0.0...  \n",
       "...                                                 ...  \n",
       "1995  [0.007958271, 0.06905828, -0.012985666, 0.0113...  \n",
       "1996  [-0.036823038, 0.03161138, -0.017325308, 0.003...  \n",
       "1997  [0.02073842, 0.056454603, 0.000992029, 0.00940...  \n",
       "1998  [0.016565206, 0.06024626, -0.0010410805, -0.01...  \n",
       "1999  [0.005492252, 0.064615436, -0.0025653813, 0.01...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_user_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我會去計算user之間的相似度，因此在替test-user推薦item之前，我會找train user中哪些與test user比較相近，就推薦這個test user那個train user會喜歡的東西~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(dataset_dir + 'user_user_similarity_matrix.pkl')):\n",
    "    df_user_user_similarity_matrix = pd.read_pickle(dataset_dir + 'user_user_similarity_matrix.pkl')\n",
    "else:\n",
    "    user_user_similarity_matrix = []\n",
    "    for train_user in range(0,1000):\n",
    "        row_similarity_list = []\n",
    "        for test_user in range(1000,2000):\n",
    "            cosine_similarity = (1-spatial.distance.cosine(df_user_embedding.iloc[train_user][\"concat_embeddings\"], df_user_embedding.iloc[test_user][\"concat_embeddings\"]))\n",
    "            row_similarity_list.append(cosine_similarity)\n",
    "        user_user_similarity_matrix.append(row_similarity_list)\n",
    "    # print(user_user_similarity_matrix)\n",
    "    columns_names = list(range(1000,2000))\n",
    "    df_user_user_similarity_matrix = pd.DataFrame(user_user_similarity_matrix, columns = columns_names)\n",
    "    df_user_user_similarity_matrix.to_pickle(dataset_dir + 'user_user_similarity_matrix.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.281648</td>\n",
       "      <td>0.208695</td>\n",
       "      <td>0.125609</td>\n",
       "      <td>0.179470</td>\n",
       "      <td>0.183822</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>0.052345</td>\n",
       "      <td>0.202675</td>\n",
       "      <td>0.335739</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173621</td>\n",
       "      <td>0.222536</td>\n",
       "      <td>0.221223</td>\n",
       "      <td>0.189922</td>\n",
       "      <td>0.258909</td>\n",
       "      <td>0.221459</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>0.253004</td>\n",
       "      <td>0.236725</td>\n",
       "      <td>0.312044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107756</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>0.171894</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.263724</td>\n",
       "      <td>0.066528</td>\n",
       "      <td>0.048420</td>\n",
       "      <td>0.140302</td>\n",
       "      <td>0.219080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188666</td>\n",
       "      <td>0.127834</td>\n",
       "      <td>0.170375</td>\n",
       "      <td>0.164114</td>\n",
       "      <td>0.132382</td>\n",
       "      <td>0.155832</td>\n",
       "      <td>0.172978</td>\n",
       "      <td>0.137667</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.184401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.340798</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>0.117053</td>\n",
       "      <td>0.121768</td>\n",
       "      <td>0.192938</td>\n",
       "      <td>0.217003</td>\n",
       "      <td>-0.007815</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>0.093833</td>\n",
       "      <td>0.201811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162832</td>\n",
       "      <td>0.347783</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.219791</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>0.166411</td>\n",
       "      <td>0.199871</td>\n",
       "      <td>0.136065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152984</td>\n",
       "      <td>0.204095</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.151933</td>\n",
       "      <td>0.109114</td>\n",
       "      <td>0.051870</td>\n",
       "      <td>0.128989</td>\n",
       "      <td>0.186338</td>\n",
       "      <td>0.399219</td>\n",
       "      <td>0.216707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244051</td>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.480642</td>\n",
       "      <td>0.195987</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.177108</td>\n",
       "      <td>0.142491</td>\n",
       "      <td>0.211308</td>\n",
       "      <td>-0.009201</td>\n",
       "      <td>0.387058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.410860</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.188938</td>\n",
       "      <td>0.215626</td>\n",
       "      <td>0.339893</td>\n",
       "      <td>0.351212</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.204705</td>\n",
       "      <td>0.207856</td>\n",
       "      <td>0.335223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293352</td>\n",
       "      <td>0.420971</td>\n",
       "      <td>0.161138</td>\n",
       "      <td>0.279038</td>\n",
       "      <td>0.344157</td>\n",
       "      <td>0.386043</td>\n",
       "      <td>0.085055</td>\n",
       "      <td>0.218188</td>\n",
       "      <td>0.275574</td>\n",
       "      <td>0.251951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.318691</td>\n",
       "      <td>0.269468</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>0.186885</td>\n",
       "      <td>0.302532</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.058353</td>\n",
       "      <td>0.258401</td>\n",
       "      <td>0.215519</td>\n",
       "      <td>0.326197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224176</td>\n",
       "      <td>0.286827</td>\n",
       "      <td>0.162822</td>\n",
       "      <td>0.274992</td>\n",
       "      <td>0.254537</td>\n",
       "      <td>0.387950</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.317955</td>\n",
       "      <td>0.197057</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.246249</td>\n",
       "      <td>0.342056</td>\n",
       "      <td>0.188454</td>\n",
       "      <td>0.261937</td>\n",
       "      <td>0.381595</td>\n",
       "      <td>0.282175</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.282524</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>0.293508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296109</td>\n",
       "      <td>0.172917</td>\n",
       "      <td>0.195978</td>\n",
       "      <td>0.312822</td>\n",
       "      <td>0.194241</td>\n",
       "      <td>0.184523</td>\n",
       "      <td>0.052026</td>\n",
       "      <td>0.216403</td>\n",
       "      <td>0.212665</td>\n",
       "      <td>0.304270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.253551</td>\n",
       "      <td>0.193244</td>\n",
       "      <td>0.278929</td>\n",
       "      <td>0.220450</td>\n",
       "      <td>0.320774</td>\n",
       "      <td>0.388695</td>\n",
       "      <td>0.158398</td>\n",
       "      <td>0.211402</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>0.186920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220253</td>\n",
       "      <td>0.273932</td>\n",
       "      <td>0.362760</td>\n",
       "      <td>0.306700</td>\n",
       "      <td>0.410991</td>\n",
       "      <td>0.453089</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>0.230232</td>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.406711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.232465</td>\n",
       "      <td>0.211833</td>\n",
       "      <td>0.121255</td>\n",
       "      <td>0.133941</td>\n",
       "      <td>0.225623</td>\n",
       "      <td>0.214997</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.195395</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.203365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160095</td>\n",
       "      <td>0.239532</td>\n",
       "      <td>0.179513</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.376211</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.250970</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.201342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.388990</td>\n",
       "      <td>0.280651</td>\n",
       "      <td>0.182958</td>\n",
       "      <td>0.279766</td>\n",
       "      <td>0.207126</td>\n",
       "      <td>0.254176</td>\n",
       "      <td>-0.036328</td>\n",
       "      <td>0.122361</td>\n",
       "      <td>0.082163</td>\n",
       "      <td>0.327857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273888</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.094534</td>\n",
       "      <td>0.209046</td>\n",
       "      <td>0.125721</td>\n",
       "      <td>0.165480</td>\n",
       "      <td>0.060655</td>\n",
       "      <td>0.230642</td>\n",
       "      <td>0.180086</td>\n",
       "      <td>0.159151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1000      1001      1002      1003      1004      1005      1006  \\\n",
       "0    0.281648  0.208695  0.125609  0.179470  0.183822  0.109009  0.052345   \n",
       "1    0.107756  0.157925  0.171894  0.191783  0.215627  0.263724  0.066528   \n",
       "2    0.340798  0.104089  0.117053  0.121768  0.192938  0.217003 -0.007815   \n",
       "3    0.152984  0.204095  0.054092  0.151933  0.109114  0.051870  0.128989   \n",
       "4    0.410860  0.238368  0.188938  0.215626  0.339893  0.351212  0.086864   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.318691  0.269468  0.119631  0.186885  0.302532  0.243200  0.058353   \n",
       "996  0.246249  0.342056  0.188454  0.261937  0.381595  0.282175  0.023506   \n",
       "997  0.253551  0.193244  0.278929  0.220450  0.320774  0.388695  0.158398   \n",
       "998  0.232465  0.211833  0.121255  0.133941  0.225623  0.214997  0.058819   \n",
       "999  0.388990  0.280651  0.182958  0.279766  0.207126  0.254176 -0.036328   \n",
       "\n",
       "         1007      1008      1009  ...      1990      1991      1992  \\\n",
       "0    0.202675  0.335739  0.217125  ...  0.173621  0.222536  0.221223   \n",
       "1    0.048420  0.140302  0.219080  ...  0.188666  0.127834  0.170375   \n",
       "2    0.082012  0.093833  0.201811  ...  0.162832  0.347783  0.093973   \n",
       "3    0.186338  0.399219  0.216707  ...  0.244051  0.087133  0.480642   \n",
       "4    0.204705  0.207856  0.335223  ...  0.293352  0.420971  0.161138   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.258401  0.215519  0.326197  ...  0.224176  0.286827  0.162822   \n",
       "996  0.282524  0.276801  0.293508  ...  0.296109  0.172917  0.195978   \n",
       "997  0.211402  0.324682  0.186920  ...  0.220253  0.273932  0.362760   \n",
       "998  0.195395  0.183076  0.203365  ...  0.160095  0.239532  0.179513   \n",
       "999  0.122361  0.082163  0.327857  ...  0.273888  0.220284  0.094534   \n",
       "\n",
       "         1993      1994      1995      1996      1997      1998      1999  \n",
       "0    0.189922  0.258909  0.221459  0.169270  0.253004  0.236725  0.312044  \n",
       "1    0.164114  0.132382  0.155832  0.172978  0.137667  0.036835  0.184401  \n",
       "2    0.229857  0.219791  0.337218 -0.006569  0.166411  0.199871  0.136065  \n",
       "3    0.195987  0.244529  0.177108  0.142491  0.211308 -0.009201  0.387058  \n",
       "4    0.279038  0.344157  0.386043  0.085055  0.218188  0.275574  0.251951  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.274992  0.254537  0.387950  0.023907  0.317955  0.197057  0.175260  \n",
       "996  0.312822  0.194241  0.184523  0.052026  0.216403  0.212665  0.304270  \n",
       "997  0.306700  0.410991  0.453089  0.130172  0.230232  0.169021  0.406711  \n",
       "998  0.185097  0.231373  0.376211  0.013491  0.250970  0.063096  0.201342  \n",
       "999  0.209046  0.125721  0.165480  0.060655  0.230642  0.180086  0.159151  \n",
       "\n",
       "[1000 rows x 1000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_user_user_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating User-Item Similarity matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the latest dataframe\n",
    "\n",
    "接著我會把最像的user (in train user) 推薦item的順序如法炮製給這個test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1    -1.000000  0.055316  0.112049  0.171833  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_user_item_similarity_latest = pd.read_pickle('./dataset/test/epoch_119.pkl')\n",
    "display(df_user_item_similarity_latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the test user to item similarity\n",
    "\n",
    "更新這個user-item的矩陣\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_user in range(1000, 2000):\n",
    "#     # print(\"Origin similarity:\", df_user_item_similarity_latest.iloc[test_user][0])\n",
    "#     column_data = df_user_user_similarity_matrix[test_user]\n",
    "#     top_three_similarity = column_data.nlargest(3) # top3 user and its similarity\n",
    "#     sum_of_similarities = top_three_similarity.sum() # used to normalized\n",
    "#     normalized_list = [top_three_similarity.iloc[0]/sum_of_similarities, top_three_similarity.iloc[1]/sum_of_similarities, top_three_similarity.iloc[2]/sum_of_similarities]\n",
    "#     # print(top_three_similarity)\n",
    "#     # print(\"Top 3 similar user: \", top_three_similarity.index[0], top_three_similarity.index[1], top_three_similarity.index[2])\n",
    "#     # print(\"We should multiply their similarity to :\", normalized_list)\n",
    "#     # print(f\"Origin similarity of item 0 is {df_user_item_similarity_latest.iloc[top_three_similarity.index[0]][0]}, {df_user_item_similarity_latest.iloc[top_three_similarity.index[1]][0]}, {df_user_item_similarity_latest.iloc[top_three_similarity.index[2]][0]}\")\n",
    "#     new_similarity_list = df_user_item_similarity_latest.iloc[top_three_similarity.index[0]] * normalized_list[0] + df_user_item_similarity_latest.iloc[top_three_similarity.index[1]] * normalized_list[1] + df_user_item_similarity_latest.iloc[top_three_similarity.index[2]] * normalized_list[2]\n",
    "#     # print(\"After update, the new similarity of user item is :\", new_similarity_list[0])\n",
    "#     df_user_item_similarity_latest.iloc[test_user] = df_user_item_similarity_latest.iloc[top_three_similarity.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.171833</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1    -1.000000  0.055316  0.112049  0.171833  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_user_item_similarity_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experience Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_info = {uid: {} for uid in range(N_TEST_USERS)}  # for every element: {user_id: {item_id: click_count}}\n",
    "\n",
    "with open('./dataset/clicked_ids_output_final.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().split(', ')\n",
    "        user_id = int(line[0])\n",
    "        item_id = int(line[1])\n",
    "        \n",
    "        try:\n",
    "            user_item_info[user_id][item_id] += 1\n",
    "        except KeyError:\n",
    "            user_item_info[user_id][item_id] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most alike user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_user_id in range(1000, 2000):\n",
    "#     # print(\"Origin similarity:\", df_user_item_similarity_latest.iloc[test_user][0])\n",
    "#     column_data = df_user_user_similarity_matrix[test_user_id]\n",
    "#     most_alike_user = column_data.nlargest(1) # most alike user and its similarity\n",
    "#     most_alike_user_id = most_alike_user.index[0]\n",
    "#     user_item_info[test_user_id] = user_item_info[most_alike_user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 3 alike user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure test user is empty dict\n",
    "for uid in range(1000, 2000):\n",
    "    user_item_info[uid] = {}\n",
    "\n",
    "for test_user_id in range(1000, 2000):\n",
    "    # print(\"Origin similarity:\", df_user_item_similarity_latest.iloc[test_user][0])\n",
    "    column_data = df_user_user_similarity_matrix[test_user_id]\n",
    "    top_three_similarity = column_data.nlargest(3) # top 3 alike user and its similarity\n",
    "    \n",
    "    sum_of_similarities = top_three_similarity.sum() # used to normalized\n",
    "    normalized_list = [top_three_similarity.iloc[i]/sum_of_similarities for i in range(3)]\n",
    "    # print(normalized_list, \"\\n\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        alike_user_id = top_three_similarity.index[i]\n",
    "        interest_items = list(user_item_info[alike_user_id].keys())\n",
    "        interest_count = list(user_item_info[alike_user_id].values())\n",
    "        interest_count = [x * normalized_list[i] for x in interest_count]\n",
    "                \n",
    "        for j in range(len(interest_items)):\n",
    "            item_id = interest_items[j]\n",
    "            item_count = interest_count[j]\n",
    "            try:\n",
    "                user_item_info[test_user_id][item_id] += item_count\n",
    "            except KeyError:\n",
    "                user_item_info[test_user_id][item_id] = item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1702.67it/s]\n"
     ]
    }
   ],
   "source": [
    "Items = {}\n",
    "Weights = {}\n",
    "\n",
    "for user_id in tqdm(range(N_TEST_USERS)):\n",
    "    Items[user_id] = list(user_item_info[user_id].keys())\n",
    "    interest_count = np.array(list(user_item_info[user_id].values()))\n",
    "    total_count = interest_count.sum()\n",
    "    Weights[user_id] = interest_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 270942it [14:17, 316.07it/s]\n",
      "Testing: 270415it [14:11, 317.62it/s]\n",
      "Testing: 272063it [14:11, 319.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.780667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.025167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.020667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.003167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  avg_score\n",
       "0           0   0.010000\n",
       "1           1   0.780667\n",
       "2           2   0.025167\n",
       "3           3   0.030333\n",
       "4           4   0.020667\n",
       "...       ...        ...\n",
       "1995     1995   0.003167\n",
       "1996     1996   0.003500\n",
       "1997     1997   0.002833\n",
       "1998     1998   0.002500\n",
       "1999     1999   0.002500\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(TESTING):\n",
    "    # Initialize the testing environment\n",
    "    test_env = TestingEnvironment()\n",
    "    scores = []\n",
    "\n",
    "    # The item_ids here is for the random recommender\n",
    "    item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "    # Repeat the testing process for 5 times\n",
    "    for _ in range(3):\n",
    "        # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "        # [TODO] Code for loading your model weights...\n",
    "        # df_test_similarity = df_user_item_similarity_latest.copy() # reload from train\n",
    "        current_weights = copy.deepcopy(Weights)\n",
    "        \n",
    "        # Start the testing process\n",
    "        with tqdm(desc='Testing') as pbar:\n",
    "            # Run as long as there exist some active users\n",
    "            while test_env.has_next_state():\n",
    "                # Get the current user id\n",
    "                cur_user = test_env.get_state()\n",
    "\n",
    "                # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "                # [TODO] Code for generating the recommended slate...\n",
    "                # Here we provide a simple random implementation\n",
    "                # slate = random.sample(item_ids, k=SLATE_SIZE)\n",
    "\n",
    "                interest_items = Items[cur_user]\n",
    "                weight = current_weights[cur_user]\n",
    "                \n",
    "                slate = random.choices(interest_items, weight, k=5)\n",
    "                while len(np.unique(slate)) != SLATE_SIZE:\n",
    "                    slate = random.choices(interest_items, weight, k=5)\n",
    "    \n",
    "                    \n",
    "                # Get the response of the slate from the environment\n",
    "                clicked_id, in_environment = test_env.get_response(slate)\n",
    "                if (clicked_id != -1):\n",
    "                    weight_idx = interest_items.index(clicked_id)\n",
    "                    current_weights[cur_user][weight_idx] = 0\n",
    "                    \n",
    "\n",
    "                # [TODO] Update your model here (optional)\n",
    "                # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "                # [TODO] Code for updating your model...\n",
    "   \n",
    "   \n",
    "                # Update the progress indicator\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Record the score of this testing episode\n",
    "        scores.append(test_env.get_score())\n",
    "\n",
    "        # Reset the testing environment\n",
    "        test_env.reset()\n",
    "\n",
    "        # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "        # [TODO] Code for deleting your model weights...\n",
    "        # df_test_similarity = df_user_item_similarity.copy()\n",
    "    # Calculate the average scores \n",
    "    avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "    # Generate a DataFrame to output the result in a .csv file\n",
    "    df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "    df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "    display(df_result)\n",
    "else:\n",
    "    print(\"Not to test this time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test score:135.57\n",
      "eval metric: 0.932215\n"
     ]
    }
   ],
   "source": [
    "if(TESTING):\n",
    "    total_score = df_result['avg_score'].sum()\n",
    "    print(f\"Total test score:{total_score}\")\n",
    "    print(f\"eval metric: {1-total_score/2000}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "- Ranking of **private** leaderboard of the Kaggle competition. (80%)\n",
    "- Report. (20%)\n",
    "\n",
    "### How is the Score For Ranking Calculated:\n",
    "\n",
    "We will calculate the MAE (Mean Absolute Error) between your submitted `output.csv` and a \"ground-truth\" of all 1s. The lower the better.\n",
    "\n",
    "### Your Report Should Contain:\n",
    "\n",
    "- Models you have tried during the competition. Briefly describe the main idea of the model and the reason why you chose that model.\n",
    "- List the experiments you have done. For instance, data collecting, utilizing the user / item datasets, hyperparameters tuning, training process, and so on.\n",
    "- Discussions, lessons learned, or anything else worth mentioning.\n",
    "- **Ensure your report notebook contains your training and testing code. We will re-run your code if we find your score on Kaggle suspicious.**\n",
    "\n",
    "Please name your report as `DL_comp4_{Your Team name}_report.ipynb.` and submit your report to the eeclass system before the deadline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Can Do\n",
    "\n",
    "- Implement any recommender models.\n",
    "- Collect data through accessing the **public methods provided by the environments** (i.e. methods listed in the ***Environment Public Methods*** section) and train your model.\n",
    "- Use the provided user history data (`dataset/user_data.json`) and item text description data (`dataset/item_data.json`) as auxiliary data to aid your model training.\n",
    "- Update the model during one testing episode while **following the rules mentioned in the ***Testing*** section.**\n",
    "- You can use a pretrained text encoder if you need text embeddings for the item text descriptions. **(This is the only part you can use a pretrained model in this competition.)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You CAN NOT Do\n",
    "\n",
    "- Use any dataset other than the provided ones. Using the original News Category Dataset is also prohibited.\n",
    "- Use any pretrained recommender models.\n",
    "- Plagiarize other teams' work.\n",
    "- Hack our simulation environments. Any attempt of accessing or modifying the data files in the `evaluation` directory, modifying the source code of the environments, accessing or modifying the private attributes and methods (i.e. methods and attributes not listed in the ***Environment Public Methods*** section), not following the rules in the ***Testing*** section, or any other forbidden actions mentioned in the previous section of the notebook will be regarded as cheating."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Timeline\n",
    "\n",
    "- 2024/01/08 (Mon): Competition launched.\n",
    "- 2024/01/15 (Mon) 08:00 (TW): Competition deadline.\n",
    "- 2024/01/16 (Tue) 12:00 (TW): Report deadline.\n",
    "- 2024/01/16 (Tue) 15:30 (TW): Top-3 teams sharing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Misra, Rishabh. \"News Category Dataset.\" arXiv preprint arXiv:2209.11429 (2022).\n",
    "2. Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
