{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 4: Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 03:06:06.930832: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 03:06:07.864239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.864411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.868448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.868588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.868680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.868766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.869727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 03:06:07.870520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.870627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:07.870717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:08.201433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:08.201575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:08.201669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-01-15 03:06:08.201744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5272 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5\n",
    "\n",
    "\n",
    "# parameters\n",
    "MODEL_PATH = \"./model_NN\"\n",
    "CKP_DIR = \"./checkpoints/NN\"\n",
    "\n",
    "# FunkSVD hyperparameters\n",
    "EMBEDDING_SIZE = 50\n",
    "BATCH_SIZE = 128\n",
    "INITIAL_N_EPOCHS = 100\n",
    "N_EPOCHS = 25\n",
    "LEARNING_RATE = 5e-5\n",
    "TRAINING_EPISODES = 500\n",
    "\n",
    "\n",
    "# Q-learning\n",
    "# agent\n",
    "MIN_EXPLORING_RATE = 0.01\n",
    "MIN_LEARNING_RATE = 0.5\n",
    "\n",
    "# training\n",
    "NUM_EPISODE = 40000\n",
    "PRINT_EVERY_EPISODE = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "USER_ITEM_SIMILARITY = os.path.join('dataset', 'user_item_similarity.pkl')\n",
    "INTERACT_DATA = os.path.join('dataset', 'organized_interact_data.pkl')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[42558, 65272, 13353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[146057, 195688, 143652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[67551, 85247, 33714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[116097, 192703, 103229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[68756, 140123, 135289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[95090, 131393, 130239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[2360, 147130, 8145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[99794, 138694, 157888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[55561, 60372, 51442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[125409, 77906, 124792]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   history\n",
       "0           0     [42558, 65272, 13353]\n",
       "1           1  [146057, 195688, 143652]\n",
       "2           2     [67551, 85247, 33714]\n",
       "3           3  [116097, 192703, 103229]\n",
       "4           4   [68756, 140123, 135289]\n",
       "...       ...                       ...\n",
       "1995     1995   [95090, 131393, 130239]\n",
       "1996     1996      [2360, 147130, 8145]\n",
       "1997     1997   [99794, 138694, 157888]\n",
       "1998     1998     [55561, 60372, 51442]\n",
       "1999     1999   [125409, 77906, 124792]\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \n",
       "0       Health experts said it is too early to predict...  \n",
       "1       He was subdued by passengers and crew when he ...  \n",
       "2       \"Until you have a dog you don't understand wha...  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  \n",
       "...                                                   ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...  \n",
       "209525  CORRECTION: An earlier version of this story i...  \n",
       "209526  The five-time all-star center tore into his te...  \n",
       "\n",
       "[209527 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>209517</th>\n",
       "      <th>209518</th>\n",
       "      <th>209519</th>\n",
       "      <th>209520</th>\n",
       "      <th>209521</th>\n",
       "      <th>209522</th>\n",
       "      <th>209523</th>\n",
       "      <th>209524</th>\n",
       "      <th>209525</th>\n",
       "      <th>209526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062287</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>0.013853</td>\n",
       "      <td>0.226747</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.196566</td>\n",
       "      <td>0.109174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.075266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221764</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>0.091024</td>\n",
       "      <td>0.078525</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>0.038990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>-0.012615</td>\n",
       "      <td>-0.014647</td>\n",
       "      <td>0.126634</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>-0.061269</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.029401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>0.099989</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.098932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.170552</td>\n",
       "      <td>0.072513</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>0.203117</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.225814</td>\n",
       "      <td>0.183863</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.209297</td>\n",
       "      <td>0.033176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.129592</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.170305</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.190394</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.082865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060153</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>-0.026443</td>\n",
       "      <td>-0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.095109</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>0.087014</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.112063</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045567</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.040877</td>\n",
       "      <td>0.201333</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.176499</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.040855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.084990</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.165294</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.103643</td>\n",
       "      <td>0.136623</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.035067</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>0.071645</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>0.179517</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094536</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.195310</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>0.038926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 209527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6       \\\n",
       "0     0.062287  0.003323  0.261205  0.274883  0.064868  0.013853  0.226747   \n",
       "1     0.221764  0.055316  0.112049  0.190925  0.091024  0.078525  0.017141   \n",
       "2     0.106126  0.022207  0.117865  0.251699 -0.012615 -0.014647  0.126634   \n",
       "3     0.093782  0.016448  0.107896  0.075283  0.067360 -0.035875  0.099989   \n",
       "4     0.122536  0.071247  0.153996  0.225814  0.183863  0.045011  0.210932   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.100583  0.015665  0.170305  0.348556  0.004256  0.037536  0.147794   \n",
       "1996  0.091208  0.042278  0.095109  0.068298  0.088406  0.037034  0.087014   \n",
       "1997  0.084990  0.107297  0.142880  0.165294  0.093537  0.032139  0.144430   \n",
       "1998  0.170120  0.071936  0.222804  0.198526  0.098436 -0.000620  0.210958   \n",
       "1999  0.139319  0.033717  0.187866  0.179517  0.099115  0.010365  0.215600   \n",
       "\n",
       "        7         8         9       ...    209517    209518    209519  \\\n",
       "0     0.061278  0.196566  0.109174  ...  0.043999  0.059647  0.192302   \n",
       "1     0.173482  0.051898  0.018566  ... -0.004871 -0.035946  0.117543   \n",
       "2     0.021103  0.089571  0.015671  ...  0.036220  0.084124 -0.012249   \n",
       "3     0.168689  0.128790  0.098932  ...  0.056915  0.040844  0.170552   \n",
       "4     0.074886  0.209297  0.033176  ...  0.063099  0.134406  0.060474   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995  0.190394  0.262166  0.082865  ...  0.060153  0.081491  0.119582   \n",
       "1996  0.329571  0.112063  0.101930  ... -0.045567 -0.018176  0.064000   \n",
       "1997  0.103643  0.136623  0.098574  ...  0.043109 -0.038939  0.077905   \n",
       "1998  0.153454  0.097726  0.120007  ...  0.026999  0.008165  0.022288   \n",
       "1999  0.079645  0.057909  0.020126  ...  0.094536  0.030316  0.135116   \n",
       "\n",
       "        209520    209521    209522    209523    209524    209525    209526  \n",
       "0     0.062932  0.180494  0.012018  0.048684  0.079522 -0.015544  0.075266  \n",
       "1    -0.005578  0.029166  0.013565  0.055716  0.008542  0.073230  0.038990  \n",
       "2     0.043811  0.079477 -0.061269  0.037820  0.004233  0.000226  0.029401  \n",
       "3     0.072513  0.178354  0.060635  0.035779  0.203117  0.084404  0.080729  \n",
       "4     0.110714  0.092821  0.012666  0.129592  0.059556  0.067587  0.003772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.026745  0.165972  0.012540  0.067981  0.044060 -0.026443 -0.015400  \n",
       "1996  0.040877  0.201333  0.011241  0.077976  0.176499  0.095174  0.040855  \n",
       "1997  0.010034  0.133854  0.056863  0.035067  0.070287  0.059929  0.019807  \n",
       "1998  0.071645  0.013865  0.025776  0.133728  0.029238  0.022635  0.013028  \n",
       "1999  0.003442  0.195310  0.078064  0.013008  0.112885  0.032778  0.038926  \n",
       "\n",
       "[2000 rows x 209527 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_item_sim = pd.read_pickle(USER_ITEM_SIMILARITY)\n",
    "df_user_item_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12126</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9810</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9102</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796164</th>\n",
       "      <td>999</td>\n",
       "      <td>199848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796165</th>\n",
       "      <td>999</td>\n",
       "      <td>134616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796166</th>\n",
       "      <td>999</td>\n",
       "      <td>53478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796167</th>\n",
       "      <td>999</td>\n",
       "      <td>110229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796168</th>\n",
       "      <td>999</td>\n",
       "      <td>157136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796169 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "0             0    12126       5\n",
       "1             0     9810       5\n",
       "2             0    42558       1\n",
       "3             0    13353       1\n",
       "4             0     9102       5\n",
       "...         ...      ...     ...\n",
       "796164      999   199848       1\n",
       "796165      999   134616       1\n",
       "796166      999    53478       1\n",
       "796167      999   110229       1\n",
       "796168      999   157136       1\n",
       "\n",
       "[796169 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interact_data = pd.read_pickle(INTERACT_DATA)\n",
    "df_interact_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_size=50, hidden_units=128, learning_rate=1e-4):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        self.user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, input_length=1)\n",
    "        self.item_embedding = Embedding(input_dim=num_items, output_dim=embedding_size, input_length=1)\n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        self.mlp_layer_1 = Dense(64, activation='relu')\n",
    "        self.mlp_layer_2 = Dense(32, activation='relu')\n",
    "        self.hidden_layer = Dense(hidden_units, activation='relu')\n",
    "        self.output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_input, item_input = inputs\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "        user_flat = self.flatten(user_embedded)\n",
    "        item_flat = self.flatten(item_embedded)\n",
    "        merged = self.concat([user_flat, item_flat])\n",
    "        mlp_output = self.mlp_layer_2(self.mlp_layer_1(merged))\n",
    "        merged_with_mlp = self.concat([merged, mlp_output])\n",
    "        hidden = self.hidden_layer(merged_with_mlp)\n",
    "        output = self.output_layer(hidden)\n",
    "        return output\n",
    "    \n",
    "    @tf.function\n",
    "    def compute_loss(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        '''\n",
    "        Compute the MSE loss of the model\n",
    "        '''\n",
    "        loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function  # the function decorated by tf.function will be compiled into a callable TensorFlow graph automatically. This allows the TensorFlow runtime to apply optimizations and exploit parallelism to boost computation performance.\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # training=True is only needed if there are layers with different\n",
    "            # behavior during training versus inference (e.g. Dropout).\n",
    "\n",
    "            user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "            item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "            y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "            y_pred = self([user_ids, item_ids])\n",
    "            loss = self.compute_loss(y_true, y_pred)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def val_step(self, data):\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(data[:, 2], dtype=tf.float32)\n",
    "\n",
    "        y_pred = self([user_ids, item_ids])\n",
    "        loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205995</th>\n",
       "      <td>1999</td>\n",
       "      <td>119308</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205996</th>\n",
       "      <td>1999</td>\n",
       "      <td>98758</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205997</th>\n",
       "      <td>1999</td>\n",
       "      <td>115028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205998</th>\n",
       "      <td>1999</td>\n",
       "      <td>133118</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205999</th>\n",
       "      <td>1999</td>\n",
       "      <td>98047</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "0             0    42558       5\n",
       "1             0    65272       5\n",
       "2             0    13353       5\n",
       "3             0    13353       5\n",
       "4             0    42558       5\n",
       "...         ...      ...     ...\n",
       "205995     1999   119308       4\n",
       "205996     1999    98758       4\n",
       "205997     1999   115028       4\n",
       "205998     1999   133118       4\n",
       "205999     1999    98047       4\n",
       "\n",
       "[206000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for i in range(N_TEST_USERS):\n",
    "    for item in df_user.iloc[i][\"history\"]:\n",
    "        temp.append([df_user[\"user_id\"][i], item, 5])\n",
    "\n",
    "    sorted_indices = np.argsort(df_user_item_sim.iloc[i])[::-1]\n",
    "    for item in sorted_indices[:10]:\n",
    "        temp.append([df_user[\"user_id\"][i], item, 5])\n",
    "    for item in sorted_indices[10:100]:\n",
    "        temp.append([df_user[\"user_id\"][i], item, 4])\n",
    "    # for item in sorted_indices[100:1000]:\n",
    "    #     temp.append([df_user[\"user_id\"][i], item, 3])\n",
    "\n",
    "df_augmentation = pd.DataFrame(temp, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "df_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002164</th>\n",
       "      <td>999</td>\n",
       "      <td>199848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002165</th>\n",
       "      <td>999</td>\n",
       "      <td>134616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002166</th>\n",
       "      <td>999</td>\n",
       "      <td>53478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002167</th>\n",
       "      <td>999</td>\n",
       "      <td>110229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002168</th>\n",
       "      <td>999</td>\n",
       "      <td>157136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002169 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0              0    42558       5\n",
       "1              0    65272       5\n",
       "2              0    13353       5\n",
       "3              0    13353       5\n",
       "4              0    42558       5\n",
       "...          ...      ...     ...\n",
       "1002164      999   199848       1\n",
       "1002165      999   134616       1\n",
       "1002166      999    53478       1\n",
       "1002167      999   110229       1\n",
       "1002168      999   157136       1\n",
       "\n",
       "[1002169 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.concat([df_augmentation, df_interact_data], axis=0, ignore_index=True)\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<00:00, 2092.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataframes = []\n",
    "val_dataframes = []\n",
    "\n",
    "for i in tqdm(range(N_TEST_USERS)):\n",
    "    user_all = df_ratings[df_ratings['user_id'] == i]\n",
    "    user_train = user_all.iloc[3:]\n",
    "    user_val = user_all.iloc[:3]\n",
    "    # assert len(user_train) == 100\n",
    "    assert len(user_val) == 3\n",
    "    train_dataframes.append(user_train)\n",
    "    val_dataframes.append(user_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9810</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996164</th>\n",
       "      <td>1999</td>\n",
       "      <td>119308</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996165</th>\n",
       "      <td>1999</td>\n",
       "      <td>98758</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996166</th>\n",
       "      <td>1999</td>\n",
       "      <td>115028</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996167</th>\n",
       "      <td>1999</td>\n",
       "      <td>133118</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996168</th>\n",
       "      <td>1999</td>\n",
       "      <td>98047</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996169 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating\n",
       "0             0    13353     1.0\n",
       "1             0    42558     1.0\n",
       "2             0    65272     1.0\n",
       "3             0     9810     1.0\n",
       "4             0     9102     1.0\n",
       "...         ...      ...     ...\n",
       "996164     1999   119308     0.5\n",
       "996165     1999    98758     0.5\n",
       "996166     1999   115028     0.5\n",
       "996167     1999   133118     0.5\n",
       "996168     1999    98047     0.5\n",
       "\n",
       "[996169 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all per-user training sets\n",
    "df_train = pd.concat(train_dataframes, ignore_index=True)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "df_train_norm = df_train.copy(deep=True)\n",
    "df_train_norm['rating'] -= 3\n",
    "df_train_norm['rating'] /= 2\n",
    "df_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>146057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>195688</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1998</td>\n",
       "      <td>60372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1998</td>\n",
       "      <td>51442</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>1999</td>\n",
       "      <td>125409</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1999</td>\n",
       "      <td>77906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1999</td>\n",
       "      <td>124792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "0           0    42558     1.0\n",
       "1           0    65272     1.0\n",
       "2           0    13353     1.0\n",
       "3           1   146057     1.0\n",
       "4           1   195688     1.0\n",
       "...       ...      ...     ...\n",
       "5995     1998    60372     1.0\n",
       "5996     1998    51442     1.0\n",
       "5997     1999   125409     1.0\n",
       "5998     1999    77906     1.0\n",
       "5999     1999   124792     1.0\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all per-user validation sets\n",
    "df_val = pd.concat(val_dataframes, ignore_index=True)\n",
    "\n",
    "# normalize the ratings (may be beneficial to some models)\n",
    "# here we make a copy of the un-normalized validation set for evaluation\n",
    "df_val_norm = df_val.copy(deep=True)\n",
    "df_val_norm['rating'] -= 3\n",
    "df_val_norm['rating'] /= 2\n",
    "df_val_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_train_norm)\n",
    "dataset_train = dataset_train.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE, drop_remainder=True)\\\n",
    "                             .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(df_val_norm)\n",
    "dataset_val = dataset_val.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE, drop_remainder=True)\\\n",
    "                         .prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log2(x: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.math.log(tf.cast(x, tf.float32)) / tf.math.log(2.)\n",
    "\n",
    "@tf.function\n",
    "def ndcg_at_5(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    y_pred = y_pred[:5]\n",
    "    idx = tf.equal(tf.cast(y_pred, tf.int32), tf.cast(y_true, tf.int32))\n",
    "    if tf.reduce_sum(tf.cast(idx, tf.int32)) > 0:\n",
    "        return 1. / log2(2 + tf.argmax(idx))\n",
    "    else:\n",
    "        return tf.constant(0.)\n",
    "\n",
    "@tf.function\n",
    "def recall_at_5(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    y_pred = y_pred[:5]\n",
    "    idx = tf.equal(tf.cast(y_pred, tf.int32), tf.cast(y_true, tf.int32))\n",
    "    if tf.reduce_sum(tf.cast(idx, tf.int32)) > 0:\n",
    "        return tf.constant(1.)\n",
    "    else:\n",
    "        return tf.constant(0.)\n",
    "\n",
    "def evaluate(model: tf.keras.Model, dataset: tf.data.Dataset) -> tuple:\n",
    "    '''\n",
    "    For each data point in the dataset:\n",
    "    data[0] is the UserID\n",
    "    data[1] is the ItemID \n",
    "    data[2] is the Rating\n",
    "    '''\n",
    "    ndcg_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for data in tqdm(dataset, desc='Evaluating'):\n",
    "        # query the model to make predictions if the observed event is a positive interaction (ratings >= 4)\n",
    "        if data[2] >= 4:\n",
    "            y_pred = model.eval_predict_onestep(tf.gather(data, 0))\n",
    "            # print(f\"y_pred:{y_pred}\")\n",
    "            y_true = tf.gather(data, 1)\n",
    "            # print(f\"y_true:{y_true}\")\n",
    "            ndcg = ndcg_at_5(y_true, y_pred)\n",
    "            recall = recall_at_5(y_true, y_pred)\n",
    "            ndcg_scores.append(ndcg)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "    ndcg_result = tf.reduce_mean(ndcg_scores).numpy()\n",
    "    recall_result = tf.reduce_mean(recall_scores).numpy()\n",
    "\n",
    "    return ndcg_result, recall_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = RecommenderModel(num_users=N_TEST_USERS, num_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from epoch 13\n"
     ]
    }
   ],
   "source": [
    "ckp = tf.train.latest_checkpoint(CKP_DIR)\n",
    "if ckp:\n",
    "    init_epoch = (int(ckp.split('-')[-1]))\n",
    "    ckpt = tf.train.Checkpoint(epoch=tf.Variable(init_epoch), model=model)\n",
    "    ckpt.restore(ckp)\n",
    "    print(f'Resume training from epoch {init_epoch}')\n",
    "else:\n",
    "    init_epoch = 1\n",
    "    ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), model=model)\n",
    "    print(f'Start training from epoch {init_epoch}')\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, CKP_DIR, max_to_keep=3, checkpoint_name='NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 03:07:06.471341: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train_loss: 0.8331, val_loss: 0.4374\n",
      "Saved checkpoint for epoch 14: ./checkpoints/NN/NN-14\n",
      "Epoch 2 train_loss: 0.8331, val_loss: 0.4532\n",
      "Saved checkpoint for epoch 15: ./checkpoints/NN/NN-15\n",
      "Epoch 3 train_loss: 0.8331, val_loss: 0.4919\n",
      "Saved checkpoint for epoch 16: ./checkpoints/NN/NN-16\n",
      "Epoch 4 train_loss: 0.8330, val_loss: 0.4858\n",
      "Saved checkpoint for epoch 17: ./checkpoints/NN/NN-17\n",
      "Epoch 5 train_loss: 0.8330, val_loss: 0.4548\n",
      "Saved checkpoint for epoch 18: ./checkpoints/NN/NN-18\n",
      "Epoch 6 train_loss: 0.8330, val_loss: 0.4682\n",
      "Saved checkpoint for epoch 19: ./checkpoints/NN/NN-19\n",
      "Epoch 7 train_loss: 0.8330, val_loss: 0.4884\n",
      "Saved checkpoint for epoch 20: ./checkpoints/NN/NN-20\n",
      "Epoch 8 train_loss: 0.8330, val_loss: 0.5105\n",
      "Saved checkpoint for epoch 21: ./checkpoints/NN/NN-21\n",
      "Epoch 9 train_loss: 0.8330, val_loss: 0.5433\n",
      "Saved checkpoint for epoch 22: ./checkpoints/NN/NN-22\n",
      "Epoch 10 train_loss: 0.8330, val_loss: 0.5498\n",
      "Saved checkpoint for epoch 23: ./checkpoints/NN/NN-23\n",
      "Epoch 11 train_loss: 0.8329, val_loss: 0.5301\n",
      "Saved checkpoint for epoch 24: ./checkpoints/NN/NN-24\n",
      "Epoch 12 train_loss: 0.8329, val_loss: 0.5255\n",
      "Saved checkpoint for epoch 25: ./checkpoints/NN/NN-25\n",
      "Epoch 13 train_loss: 0.8329, val_loss: 0.5430\n",
      "Saved checkpoint for epoch 26: ./checkpoints/NN/NN-26\n",
      "Epoch 14 train_loss: 0.8330, val_loss: 0.5582\n",
      "Saved checkpoint for epoch 27: ./checkpoints/NN/NN-27\n",
      "Epoch 15 train_loss: 0.8329, val_loss: 0.5388\n",
      "Saved checkpoint for epoch 28: ./checkpoints/NN/NN-28\n",
      "Epoch 16 train_loss: 0.8329, val_loss: 0.5404\n",
      "Saved checkpoint for epoch 29: ./checkpoints/NN/NN-29\n",
      "Epoch 17 train_loss: 0.8329, val_loss: 0.5551\n",
      "Saved checkpoint for epoch 30: ./checkpoints/NN/NN-30\n",
      "Epoch 18 train_loss: 0.8328, val_loss: 0.5759\n",
      "Saved checkpoint for epoch 31: ./checkpoints/NN/NN-31\n",
      "Epoch 19 train_loss: 0.8328, val_loss: 0.5814\n",
      "Saved checkpoint for epoch 32: ./checkpoints/NN/NN-32\n",
      "Epoch 20 train_loss: 0.8328, val_loss: 0.5709\n",
      "Saved checkpoint for epoch 33: ./checkpoints/NN/NN-33\n",
      "Epoch 21 train_loss: 0.8328, val_loss: 0.5563\n",
      "Saved checkpoint for epoch 34: ./checkpoints/NN/NN-34\n",
      "Epoch 22 train_loss: 0.8328, val_loss: 0.5534\n",
      "Saved checkpoint for epoch 35: ./checkpoints/NN/NN-35\n",
      "Epoch 23 train_loss: 0.8328, val_loss: 0.5751\n",
      "Saved checkpoint for epoch 36: ./checkpoints/NN/NN-36\n",
      "Epoch 24 train_loss: 0.8327, val_loss: 0.5851\n",
      "Saved checkpoint for epoch 37: ./checkpoints/NN/NN-37\n",
      "Epoch 25 train_loss: 0.8327, val_loss: 0.5749\n",
      "Saved checkpoint for epoch 38: ./checkpoints/NN/NN-38\n",
      "Epoch 26 train_loss: 0.8327, val_loss: 0.5645\n",
      "Saved checkpoint for epoch 39: ./checkpoints/NN/NN-39\n",
      "Epoch 27 train_loss: 0.8327, val_loss: 0.5734\n",
      "Saved checkpoint for epoch 40: ./checkpoints/NN/NN-40\n",
      "Epoch 28 train_loss: 0.8327, val_loss: 0.5896\n",
      "Saved checkpoint for epoch 41: ./checkpoints/NN/NN-41\n",
      "Epoch 29 train_loss: 0.8327, val_loss: 0.5827\n",
      "Saved checkpoint for epoch 42: ./checkpoints/NN/NN-42\n",
      "Epoch 30 train_loss: 0.8327, val_loss: 0.5598\n",
      "Saved checkpoint for epoch 43: ./checkpoints/NN/NN-43\n",
      "Epoch 31 train_loss: 0.8327, val_loss: 0.5612\n",
      "Saved checkpoint for epoch 44: ./checkpoints/NN/NN-44\n",
      "Epoch 32 train_loss: 0.8327, val_loss: 0.5672\n",
      "Saved checkpoint for epoch 45: ./checkpoints/NN/NN-45\n",
      "Epoch 33 train_loss: 0.8326, val_loss: 0.5895\n",
      "Saved checkpoint for epoch 46: ./checkpoints/NN/NN-46\n",
      "Epoch 34 train_loss: 0.8326, val_loss: 0.5983\n",
      "Saved checkpoint for epoch 47: ./checkpoints/NN/NN-47\n",
      "Epoch 35 train_loss: 0.8326, val_loss: 0.5932\n",
      "Saved checkpoint for epoch 48: ./checkpoints/NN/NN-48\n",
      "Epoch 36 train_loss: 0.8326, val_loss: 0.5874\n",
      "Saved checkpoint for epoch 49: ./checkpoints/NN/NN-49\n",
      "Epoch 37 train_loss: 0.8326, val_loss: 0.5825\n",
      "Saved checkpoint for epoch 50: ./checkpoints/NN/NN-50\n",
      "Epoch 38 train_loss: 0.8326, val_loss: 0.5612\n",
      "Saved checkpoint for epoch 51: ./checkpoints/NN/NN-51\n",
      "Epoch 39 train_loss: 0.8326, val_loss: 0.5620\n",
      "Saved checkpoint for epoch 52: ./checkpoints/NN/NN-52\n",
      "Epoch 40 train_loss: 0.8326, val_loss: 0.5754\n",
      "Saved checkpoint for epoch 53: ./checkpoints/NN/NN-53\n",
      "Epoch 41 train_loss: 0.8326, val_loss: 0.5833\n",
      "Saved checkpoint for epoch 54: ./checkpoints/NN/NN-54\n",
      "Epoch 42 train_loss: 0.8326, val_loss: 0.5828\n",
      "Saved checkpoint for epoch 55: ./checkpoints/NN/NN-55\n",
      "Epoch 43 train_loss: 0.8326, val_loss: 0.5760\n",
      "Saved checkpoint for epoch 56: ./checkpoints/NN/NN-56\n",
      "Epoch 44 train_loss: 0.8326, val_loss: 0.5900\n",
      "Saved checkpoint for epoch 57: ./checkpoints/NN/NN-57\n",
      "Epoch 45 train_loss: 0.8326, val_loss: 0.5899\n",
      "Saved checkpoint for epoch 58: ./checkpoints/NN/NN-58\n",
      "Epoch 46 train_loss: 0.8326, val_loss: 0.5828\n",
      "Saved checkpoint for epoch 59: ./checkpoints/NN/NN-59\n",
      "Epoch 47 train_loss: 0.8326, val_loss: 0.5757\n",
      "Saved checkpoint for epoch 60: ./checkpoints/NN/NN-60\n",
      "Epoch 48 train_loss: 0.8326, val_loss: 0.5697\n",
      "Saved checkpoint for epoch 61: ./checkpoints/NN/NN-61\n",
      "Epoch 49 train_loss: 0.8326, val_loss: 0.5806\n",
      "Saved checkpoint for epoch 62: ./checkpoints/NN/NN-62\n",
      "Epoch 50 train_loss: 0.8326, val_loss: 0.5810\n",
      "Saved checkpoint for epoch 63: ./checkpoints/NN/NN-63\n",
      "Epoch 51 train_loss: 0.8325, val_loss: 0.5841\n",
      "Saved checkpoint for epoch 64: ./checkpoints/NN/NN-64\n",
      "Epoch 52 train_loss: 0.8326, val_loss: 0.5879\n",
      "Saved checkpoint for epoch 65: ./checkpoints/NN/NN-65\n",
      "Epoch 53 train_loss: 0.8325, val_loss: 0.5885\n",
      "Saved checkpoint for epoch 66: ./checkpoints/NN/NN-66\n",
      "Epoch 54 train_loss: 0.8326, val_loss: 0.5900\n",
      "Saved checkpoint for epoch 67: ./checkpoints/NN/NN-67\n",
      "Epoch 55 train_loss: 0.8325, val_loss: 0.5864\n",
      "Saved checkpoint for epoch 68: ./checkpoints/NN/NN-68\n",
      "Epoch 56 train_loss: 0.8325, val_loss: 0.5829\n",
      "Saved checkpoint for epoch 69: ./checkpoints/NN/NN-69\n",
      "Epoch 57 train_loss: 0.8325, val_loss: 0.5883\n",
      "Saved checkpoint for epoch 70: ./checkpoints/NN/NN-70\n",
      "Epoch 58 train_loss: 0.8325, val_loss: 0.5881\n",
      "Saved checkpoint for epoch 71: ./checkpoints/NN/NN-71\n",
      "Epoch 59 train_loss: 0.8325, val_loss: 0.5849\n",
      "Saved checkpoint for epoch 72: ./checkpoints/NN/NN-72\n",
      "Epoch 60 train_loss: 0.8325, val_loss: 0.5843\n",
      "Saved checkpoint for epoch 73: ./checkpoints/NN/NN-73\n",
      "Epoch 61 train_loss: 0.8325, val_loss: 0.5711\n",
      "Saved checkpoint for epoch 74: ./checkpoints/NN/NN-74\n",
      "Epoch 62 train_loss: 0.8325, val_loss: 0.5768\n",
      "Saved checkpoint for epoch 75: ./checkpoints/NN/NN-75\n",
      "Epoch 63 train_loss: 0.8325, val_loss: 0.5767\n",
      "Saved checkpoint for epoch 76: ./checkpoints/NN/NN-76\n",
      "Epoch 64 train_loss: 0.8325, val_loss: 0.5765\n",
      "Saved checkpoint for epoch 77: ./checkpoints/NN/NN-77\n",
      "Epoch 65 train_loss: 0.8325, val_loss: 0.5735\n",
      "Saved checkpoint for epoch 78: ./checkpoints/NN/NN-78\n",
      "Epoch 66 train_loss: 0.8325, val_loss: 0.5595\n",
      "Saved checkpoint for epoch 79: ./checkpoints/NN/NN-79\n",
      "Epoch 67 train_loss: 0.8325, val_loss: 0.5637\n",
      "Saved checkpoint for epoch 80: ./checkpoints/NN/NN-80\n",
      "Epoch 68 train_loss: 0.8325, val_loss: 0.5702\n",
      "Saved checkpoint for epoch 81: ./checkpoints/NN/NN-81\n",
      "Epoch 69 train_loss: 0.8325, val_loss: 0.5635\n",
      "Saved checkpoint for epoch 82: ./checkpoints/NN/NN-82\n",
      "Epoch 70 train_loss: 0.8325, val_loss: 0.5528\n",
      "Saved checkpoint for epoch 83: ./checkpoints/NN/NN-83\n",
      "Epoch 71 train_loss: 0.8325, val_loss: 0.5466\n",
      "Saved checkpoint for epoch 84: ./checkpoints/NN/NN-84\n",
      "Epoch 72 train_loss: 0.8325, val_loss: 0.5558\n",
      "Saved checkpoint for epoch 85: ./checkpoints/NN/NN-85\n",
      "Epoch 73 train_loss: 0.8325, val_loss: 0.5467\n",
      "Saved checkpoint for epoch 86: ./checkpoints/NN/NN-86\n",
      "Epoch 74 train_loss: 0.8325, val_loss: 0.5329\n",
      "Saved checkpoint for epoch 87: ./checkpoints/NN/NN-87\n",
      "Epoch 75 train_loss: 0.8325, val_loss: 0.5409\n",
      "Saved checkpoint for epoch 88: ./checkpoints/NN/NN-88\n",
      "Epoch 76 train_loss: 0.8325, val_loss: 0.5251\n",
      "Saved checkpoint for epoch 89: ./checkpoints/NN/NN-89\n",
      "Epoch 77 train_loss: 0.8325, val_loss: 0.5469\n",
      "Saved checkpoint for epoch 90: ./checkpoints/NN/NN-90\n",
      "Epoch 78 train_loss: 0.8325, val_loss: 0.5294\n",
      "Saved checkpoint for epoch 91: ./checkpoints/NN/NN-91\n",
      "Epoch 79 train_loss: 0.8324, val_loss: 0.5241\n",
      "Saved checkpoint for epoch 92: ./checkpoints/NN/NN-92\n",
      "Epoch 80 train_loss: 0.8325, val_loss: 0.5060\n",
      "Saved checkpoint for epoch 93: ./checkpoints/NN/NN-93\n",
      "Epoch 81 train_loss: 0.8325, val_loss: 0.5245\n",
      "Saved checkpoint for epoch 94: ./checkpoints/NN/NN-94\n",
      "Epoch 82 train_loss: 0.8324, val_loss: 0.4946\n",
      "Saved checkpoint for epoch 95: ./checkpoints/NN/NN-95\n",
      "Epoch 83 train_loss: 0.8325, val_loss: 0.5011\n",
      "Saved checkpoint for epoch 96: ./checkpoints/NN/NN-96\n",
      "Epoch 84 train_loss: 0.8324, val_loss: 0.4851\n",
      "Saved checkpoint for epoch 97: ./checkpoints/NN/NN-97\n",
      "Epoch 85 train_loss: 0.8325, val_loss: 0.4799\n",
      "Saved checkpoint for epoch 98: ./checkpoints/NN/NN-98\n",
      "Epoch 86 train_loss: 0.8325, val_loss: 0.4818\n",
      "Saved checkpoint for epoch 99: ./checkpoints/NN/NN-99\n",
      "Epoch 87 train_loss: 0.8325, val_loss: 0.4719\n",
      "Saved checkpoint for epoch 100: ./checkpoints/NN/NN-100\n",
      "Epoch 88 train_loss: 0.8325, val_loss: 0.4872\n",
      "Saved checkpoint for epoch 101: ./checkpoints/NN/NN-101\n",
      "Epoch 89 train_loss: 0.8325, val_loss: 0.4879\n",
      "Saved checkpoint for epoch 102: ./checkpoints/NN/NN-102\n",
      "Epoch 90 train_loss: 0.8324, val_loss: 0.4888\n",
      "Saved checkpoint for epoch 103: ./checkpoints/NN/NN-103\n",
      "Epoch 91 train_loss: 0.8325, val_loss: 0.4956\n",
      "Saved checkpoint for epoch 104: ./checkpoints/NN/NN-104\n",
      "Epoch 92 train_loss: 0.8324, val_loss: 0.4837\n",
      "Saved checkpoint for epoch 105: ./checkpoints/NN/NN-105\n",
      "Epoch 93 train_loss: 0.8325, val_loss: 0.4670\n",
      "Saved checkpoint for epoch 106: ./checkpoints/NN/NN-106\n",
      "Epoch 94 train_loss: 0.8324, val_loss: 0.4533\n",
      "Saved checkpoint for epoch 107: ./checkpoints/NN/NN-107\n",
      "Epoch 95 train_loss: 0.8324, val_loss: 0.4503\n",
      "Saved checkpoint for epoch 108: ./checkpoints/NN/NN-108\n",
      "Epoch 96 train_loss: 0.8324, val_loss: 0.4493\n",
      "Saved checkpoint for epoch 109: ./checkpoints/NN/NN-109\n",
      "Epoch 97 train_loss: 0.8324, val_loss: 0.4439\n",
      "Saved checkpoint for epoch 110: ./checkpoints/NN/NN-110\n",
      "Epoch 98 train_loss: 0.8324, val_loss: 0.4462\n",
      "Saved checkpoint for epoch 111: ./checkpoints/NN/NN-111\n",
      "Epoch 99 train_loss: 0.8324, val_loss: 0.4281\n",
      "Saved checkpoint for epoch 112: ./checkpoints/NN/NN-112\n",
      "Epoch 100 train_loss: 0.8325, val_loss: 0.4321\n",
      "Saved checkpoint for epoch 113: ./checkpoints/NN/NN-113\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, INITIAL_N_EPOCHS + 1):\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # training\n",
    "    for data in dataset_train:\n",
    "        loss = model.train_step(data)\n",
    "        train_loss.append(loss.numpy())\n",
    "\n",
    "    # validating\n",
    "    for data in dataset_val:\n",
    "        loss = model.val_step(data)\n",
    "        val_loss.append(loss.numpy())\n",
    "\n",
    "    # record losses\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # print losses\n",
    "    print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # save checkpoint\n",
    "    save_path = manager.save()\n",
    "    if save_path:\n",
    "        print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training curve\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with the training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/996169 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RecommenderModel' object has no attribute 'eval_predict_onestep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(df_train)\n\u001b[1;32m      2\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m dataset_train\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m----> 3\u001b[0m ndcg_result, recall_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation result: [NDCG@5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndcg_result\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall@5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall_result\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# query the model to make predictions if the observed event is a positive interaction (ratings >= 4)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 36\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_predict_onestep\u001b[49m(tf\u001b[38;5;241m.\u001b[39mgather(data, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# print(f\"y_pred:{y_pred}\")\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         y_true \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(data, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RecommenderModel' object has no attribute 'eval_predict_onestep'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_train)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_train)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = tf.data.Dataset.from_tensor_slices(df_val)\n",
    "dataset_eval = dataset_eval.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_eval)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training environment\n",
    "train_env = TrainingEnvironment()\n",
    "train_scores = []\n",
    "\n",
    "\n",
    "interact_data = []\n",
    "# Repeat the testing process for 5 times\n",
    "for i in range(TRAINING_EPISODES):\n",
    "    print(f'Episode {i+1}:')\n",
    "\n",
    "    # Start the training process\n",
    "    # Run as long as there exist some active users\n",
    "    while train_env.has_next_state():\n",
    "        # Get the current user id\n",
    "        cur_user = train_env.get_state()\n",
    "        # print(f'The current user is user {cur_user}.')\n",
    "\n",
    "        # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "        slate = model.eval_predict_onestep(cur_user)\n",
    "\n",
    "        # Get the response of the slate from the environment\n",
    "        clicked_id, in_environment = train_env.get_response(slate)\n",
    "        # print(f'The click result of recommending {slate} to user {cur_user} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "        # print(f'User {cur_user} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "\n",
    "        if clicked_id == -1:\n",
    "            for item in slate:\n",
    "                random_number = random.choice([1, 2, 3])\n",
    "                interact_data.append([cur_user, item.numpy(), random_number])\n",
    "        else:\n",
    "            interact_data.append([cur_user, clicked_id, 5])\n",
    "\n",
    "        # [TODO] Update your model here (optional)\n",
    "        ACCUMULATIVE_DATA_SIZE = 100*BATCH_SIZE\n",
    "        if len(interact_data) >= ACCUMULATIVE_DATA_SIZE:\n",
    "            print(f'Updating Model')\n",
    "            df_interact = pd.DataFrame(interact_data[:ACCUMULATIVE_DATA_SIZE], columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "            df_interact.to_csv('./interact_data/interact_data.csv', mode='a', header=False, index=False)\n",
    "            interact_data = interact_data[ACCUMULATIVE_DATA_SIZE:]\n",
    "\n",
    "            df_interact = pd.concat([df_train, df_interact], axis=0)\n",
    "            df_interact_norm = df_interact.copy(deep=True)\n",
    "            df_interact_norm['rating'] -= 3\n",
    "            df_interact_norm['rating'] /= 2\n",
    "\n",
    "            dataset_interact = tf.data.Dataset.from_tensor_slices(df_interact_norm)\n",
    "            dataset_interact = dataset_interact.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                                                .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "            \n",
    "\n",
    "            # train the model\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "\n",
    "            for epoch in range(1, N_EPOCHS + 1):\n",
    "                train_loss = []\n",
    "                val_loss = []\n",
    "                # print(f'Epoch {epoch}:')\n",
    "\n",
    "                # training\n",
    "                for data in dataset_interact:\n",
    "                    loss = model.train_step(data)\n",
    "                    train_loss.append(loss.numpy())\n",
    "\n",
    "                # validating\n",
    "                for data in dataset_val:\n",
    "                    loss = model.val_step(data)\n",
    "                    val_loss.append(loss.numpy())\n",
    "\n",
    "                # record losses\n",
    "                avg_train_loss = np.mean(train_loss)\n",
    "                avg_val_loss = np.mean(val_loss)\n",
    "                train_losses.append(avg_train_loss)\n",
    "                val_losses.append(avg_val_loss)\n",
    "\n",
    "                # print losses\n",
    "                print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}\\r', end=\"\")\n",
    "\n",
    "            print(f'')\n",
    "\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    train_scores.append(train_env.get_score())\n",
    "\n",
    "    # Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "    train_env.reset()\n",
    "    print(f'Have collected {len(interact_data)} interact data\\n')\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average scores \n",
    "avg_scores = [np.average(train_scores) for train_scores in zip(*train_scores)]\n",
    "df_train_score = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training score: {1-(df_train_score[\"avg_score\"].sum()/2000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training curve\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with the training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices(df_interact)\n",
    "variable = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_train)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = tf.data.Dataset.from_tensor_slices(df_val)\n",
    "dataset_val = dataset_val.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ndcg_result, recall_result = evaluate(model, dataset_val)\n",
    "print(f'Evaluation result: [NDCG@5: {ndcg_result:.6f}, Recall@5: {recall_result:.6f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save FunkSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(1):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "    funk_SVD = FunkSVDRecommender(m_users=N_TEST_USERS, n_items=N_ITEMS, embedding_size=EMBEDDING_SIZE, learning_rate=LEARNING_RATE, bias_mu=BIAS_MU)\n",
    "    funk_SVD.load_model(MODEL_PATH)\n",
    "\n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            # slate = random.sample(item_ids, k=SLATE_SIZE)\n",
    "            slate = funk_SVD.eval_predict_onestep(cur_user)\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'testing score: {1-(df_result[\"avg_score\"].sum()/2000)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-GPU-Eric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
